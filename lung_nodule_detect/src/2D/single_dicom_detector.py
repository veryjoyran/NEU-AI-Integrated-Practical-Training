"""
ä¿®æ­£ç‰ˆå•å¼ DICOMæ£€æµ‹å™¨ - é€šè¿‡importå¯¼å…¥ç°æœ‰æ¨¡å—
Author: veryjoyran
Date: 2025-06-24 09:12:56
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import tempfile
from datetime import datetime
import json

# MonAIç›¸å…³å¯¼å…¥
from monai.transforms import (
    Compose, LoadImaged, EnsureChannelFirstd, ToTensord
)
from monai.bundle import ConfigParser
from monai.networks.nets import BasicUNet
from scipy import ndimage
from skimage import morphology
import zipfile

# ğŸ”¥ å¯¼å…¥ç°æœ‰çš„DICOMå¤„ç†å™¨æ¨¡å—
try:
    from improved_dicom_processor import ImprovedDicomProcessor, MultiVersionDetector
    print("âœ… æˆåŠŸå¯¼å…¥ç°æœ‰DICOMå¤„ç†å™¨æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥DICOMå¤„ç†å™¨å¤±è´¥: {e}")
    print("âš ï¸ è¯·ç¡®ä¿improved_dicom_processor.pyæ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹")
    raise

# ğŸ”§ ä¿®å¤ä¸­æ–‡å­—ä½“æ˜¾ç¤ºé—®é¢˜
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

print(f"ğŸ”§ PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"ğŸ‘¤ å½“å‰ç”¨æˆ·: veryjoyran")
print(f"ğŸ“… å½“å‰æ—¶é—´: 2025-06-24 09:12:56")

# ================================
# BundleåŠ è½½å™¨æ¨¡å—
# ================================

class SimpleBundleLoader2D:
    """ç®€åŒ–çš„2D BundleåŠ è½½å™¨"""

    def __init__(self, bundle_path, device='cpu'):
        self.bundle_path = Path(bundle_path)
        self.device = device
        self.model = None
        self.model_info = {}

    def load_bundle_for_single_dicom(self):
        """ä¸ºå•å¼ DICOMæ£€æµ‹åŠ è½½Bundle"""
        print(f"ğŸ”„ åŠ è½½Bundle (å•å¼ DICOMæ¨¡å¼): {self.bundle_path}")

        try:
            # è§£å‹Bundle
            if self.bundle_path.suffix.lower() == '.zip':
                bundle_dir = self._extract_bundle_zip()
            else:
                bundle_dir = self.bundle_path

            # æŸ¥æ‰¾é…ç½®æ–‡ä»¶
            config_file = self._find_config_file(bundle_dir)

            if config_file:
                print(f"   æ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_file.name}")
                success = self._load_model_with_config(config_file)

                if not success:
                    print("   ä½¿ç”¨é»˜è®¤2Dæ¨¡å‹...")
                    self.model = self._create_default_2d_model()
                    self._load_weights(bundle_dir)

                print("âœ… å•å¼ DICOMæ¨¡å¼BundleåŠ è½½å®Œæˆ")
                return True
            else:
                print("âš ï¸ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤2Dæ¨¡å‹")
                self.model = self._create_default_2d_model()
                self._load_weights(bundle_dir)
                return False

        except Exception as e:
            print(f"âŒ BundleåŠ è½½å¤±è´¥: {e}")
            self.model = self._create_default_2d_model()
            return False

    def _extract_bundle_zip(self):
        """è§£å‹Bundle ZIPæ–‡ä»¶"""
        extract_dir = Path(tempfile.mkdtemp())
        with zipfile.ZipFile(self.bundle_path, 'r') as zip_ref:
            zip_ref.extractall(extract_dir)

        bundle_dirs = [d for d in extract_dir.iterdir() if d.is_dir()]
        return bundle_dirs[0] if bundle_dirs else extract_dir

    def _find_config_file(self, bundle_dir):
        """æŸ¥æ‰¾é…ç½®æ–‡ä»¶"""
        config_patterns = [
            "configs/inference.json",
            "inference.json",
            "**/inference*.json"
        ]

        for pattern in config_patterns:
            config_files = list(bundle_dir.glob(pattern))
            if config_files:
                return config_files[0]
        return None

    def _load_model_with_config(self, config_file):
        """ä½¿ç”¨é…ç½®åŠ è½½æ¨¡å‹"""
        try:
            parser = ConfigParser()
            parser.read_config(str(config_file))

            if 'network_def' in parser.config:
                print("   è§£æ3Dæ¨¡å‹å¹¶é€‚é…ä¸º2D...")
                model_3d = parser.get_parsed_content('network_def')

                # æµ‹è¯•æ˜¯å¦å¯ä»¥ç›´æ¥ç”¨äº2D
                self.model = self._adapt_to_2d(model_3d)

                if self.model is not None:
                    # åŠ è½½æƒé‡
                    if 'initialize' in parser.config:
                        initializer = parser.get_parsed_content('initialize')
                        if hasattr(initializer, '__call__'):
                            initializer()

                    self.model_info = {
                        'type': f"{model_3d.__class__.__name__}_2D_Adapted",
                        'original_type': model_3d.__class__.__name__,
                        'adapted_to_2d': True,
                        'pretrained': True
                    }

                    print(f"âœ… 3Dæ¨¡å‹æˆåŠŸé€‚é…ä¸º2D: {model_3d.__class__.__name__}")
                    return True

            return False

        except Exception as e:
            print(f"âš ï¸ é…ç½®æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def _adapt_to_2d(self, model_3d):
        """å°†3Dæ¨¡å‹é€‚é…ä¸º2D"""
        try:
            # æµ‹è¯•2Dè¾“å…¥
            test_input = torch.randn(1, 1, 256, 256).to(self.device)

            try:
                model_3d.eval()
                with torch.no_grad():
                    output = model_3d(test_input)
                print("   âœ… 3Dæ¨¡å‹ç›´æ¥æ”¯æŒ2Dè¾“å…¥")
                return model_3d
            except:
                pass

            # æµ‹è¯•å•åˆ‡ç‰‡3Dè¾“å…¥
            test_input_3d = torch.randn(1, 1, 1, 256, 256).to(self.device)

            try:
                model_3d.eval()
                with torch.no_grad():
                    output = model_3d(test_input_3d)
                print("   âœ… 3Dæ¨¡å‹æ”¯æŒå•åˆ‡ç‰‡è¾“å…¥ï¼Œåˆ›å»ºåŒ…è£…å™¨")
                return SingleSlice3DWrapper(model_3d)
            except:
                pass

            # åˆ›å»ºé»˜è®¤2Dæ¨¡å‹
            print("   åˆ›å»ºé»˜è®¤2Dæ¨¡å‹...")
            return self._create_default_2d_model()

        except Exception as e:
            print(f"   é€‚é…å¤±è´¥: {e}")
            return None

    def _create_default_2d_model(self):
        """åˆ›å»ºé»˜è®¤çš„2Dæ¨¡å‹"""
        model = BasicUNet(
            spatial_dims=2,
            in_channels=1,
            out_channels=2,
            features=(32, 64, 128, 256, 32),
            act=("LeakyReLU", {"inplace": True}),
            norm=("instance", {"affine": True}),
            dropout=0.1
        )
        print("   åˆ›å»ºé»˜è®¤2D BasicUNetæ¨¡å‹")
        return model

    def _load_weights(self, bundle_dir):
        """åŠ è½½æƒé‡"""
        try:
            weight_files = list(bundle_dir.glob("**/*.pt")) + list(bundle_dir.glob("**/*.pth"))
            if weight_files:
                weight_file = weight_files[0]
                print(f"   åŠ è½½æƒé‡: {weight_file.name}")

                checkpoint = torch.load(weight_file, map_location=self.device)

                if isinstance(checkpoint, dict):
                    state_dict = checkpoint.get('model', checkpoint.get('state_dict', checkpoint))
                else:
                    state_dict = checkpoint

                # é€‚é…æƒé‡åˆ°2D
                adapted_weights = self._adapt_weights_to_2d(state_dict)

                missing_keys, unexpected_keys = self.model.load_state_dict(adapted_weights, strict=False)

                loaded_ratio = (len(self.model.state_dict()) - len(missing_keys)) / len(self.model.state_dict())

                self.model_info.update({
                    'loaded_ratio': loaded_ratio,
                    'pretrained': loaded_ratio > 0.5
                })

                print(f"   æƒé‡åŠ è½½å®Œæˆï¼ŒæˆåŠŸç‡: {loaded_ratio:.2f}")

        except Exception as e:
            print(f"âš ï¸ æƒé‡åŠ è½½å¤±è´¥: {e}")

    def _adapt_weights_to_2d(self, state_dict_3d):
        """å°†3Dæƒé‡é€‚é…ä¸º2Dæƒé‡"""
        adapted_weights = {}

        for key, value in state_dict_3d.items():
            # æ¸…ç†é”®å
            clean_key = key
            for prefix in ['module.', 'model.', 'network.']:
                if clean_key.startswith(prefix):
                    clean_key = clean_key[len(prefix):]
                    break

            if isinstance(value, torch.Tensor):
                # å¤„ç†3Då·ç§¯æƒé‡ -> 2Då·ç§¯æƒé‡
                if 'conv' in clean_key.lower() and 'weight' in clean_key and value.dim() == 5:
                    # å–ä¸­é—´åˆ‡ç‰‡
                    adapted_value = value[:, :, value.shape[2]//2, :, :]
                    adapted_weights[clean_key] = adapted_value
                else:
                    adapted_weights[clean_key] = value
            else:
                adapted_weights[clean_key] = value

        return adapted_weights

    def get_model(self):
        """è·å–æ¨¡å‹"""
        if self.model is not None:
            self.model = self.model.to(self.device)
            self.model.eval()
        return self.model

    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return self.model_info


class SingleSlice3DWrapper(torch.nn.Module):
    """å•åˆ‡ç‰‡3DåŒ…è£…å™¨"""

    def __init__(self, model_3d):
        super().__init__()
        self.model_3d = model_3d

    def forward(self, x):
        """å°†2Dè¾“å…¥è½¬æ¢ä¸ºå•åˆ‡ç‰‡3D"""
        if x.dim() == 4:  # (B, C, H, W)
            x = x.unsqueeze(2)  # (B, C, 1, H, W)

        output = self.model_3d(x)

        # å¤„ç†è¾“å‡º
        if isinstance(output, torch.Tensor) and output.dim() == 5:
            output = output.squeeze(2)
        elif isinstance(output, dict):
            for key, value in output.items():
                if isinstance(value, torch.Tensor) and value.dim() == 5:
                    output[key] = value.squeeze(2)

        return output

# ================================
# ä¸»è¦æ£€æµ‹å™¨ç±»
# ================================

class ImprovedSingleDicomDetector:
    """æ”¹è¿›çš„å•å¼ DICOMæ£€æµ‹å™¨ - ä½¿ç”¨å¯¼å…¥çš„DICOMå¤„ç†å™¨"""

    def __init__(self, bundle_path=None, device=None):
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        self.bundle_loader = None
        self.model = None
        self.model_info = {}

        # ğŸ”¥ ä½¿ç”¨å¯¼å…¥çš„DICOMå¤„ç†å™¨
        print("ğŸ”„ åˆå§‹åŒ–å¯¼å…¥çš„DICOMå¤„ç†å™¨...")
        self.dicom_processor = ImprovedDicomProcessor()

        print(f"ğŸš€ åˆå§‹åŒ–æ”¹è¿›ç‰ˆå•å¼ DICOMæ£€æµ‹å™¨")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"   å½“å‰ç”¨æˆ·: veryjoyran")
        print(f"   æ—¶é—´: 2025-06-24 09:12:56")

        # è®¾ç½®ç®€åŒ–çš„é¢„å¤„ç†
        self.setup_minimal_transforms()

        if bundle_path:
            self.load_bundle(bundle_path)

    def setup_minimal_transforms(self):
        """è®¾ç½®æœ€å°åŒ–çš„MonAIé¢„å¤„ç†"""
        self.transforms = Compose([
            LoadImaged(keys=["image"]),
            EnsureChannelFirstd(keys=["image"]),
            ToTensord(keys=["image"]),
        ])

    def load_bundle(self, bundle_path):
        """åŠ è½½Bundle"""
        try:
            print(f"ğŸ”„ åŠ è½½Bundle: {bundle_path}")

            self.bundle_loader = SimpleBundleLoader2D(bundle_path, self.device)
            success = self.bundle_loader.load_bundle_for_single_dicom()

            self.model = self.bundle_loader.get_model()
            self.model_info = self.bundle_loader.get_model_info()

            if self.model is None:
                raise Exception("æ¨¡å‹åŠ è½½å¤±è´¥")

            print(f"âœ… BundleåŠ è½½å®Œæˆ")
            print(f"   æ¨¡å‹ç±»å‹: {self.model_info.get('type', 'Unknown')}")

            return True

        except Exception as e:
            print(f"âŒ BundleåŠ è½½å¤±è´¥: {e}")
            return False

    def detect_with_improved_preprocessing(self, dicom_path,
                                         window_center=50, window_width=350,
                                         test_all_versions=True):
        """ä½¿ç”¨æ”¹è¿›çš„é¢„å¤„ç†è¿›è¡Œæ£€æµ‹"""
        print(f"ğŸ” å¼€å§‹æ”¹è¿›ç‰ˆDICOMæ£€æµ‹")
        print(f"   DICOMæ–‡ä»¶: {Path(dicom_path).name}")
        print(f"   çª—å®½çª—ä½: C={window_center}, W={window_width}")

        if self.model is None:
            print("âŒ æ¨¡å‹æœªåŠ è½½")
            return None

        if test_all_versions:
            # ğŸ”¥ ä½¿ç”¨å¯¼å…¥çš„MultiVersionDetector
            print("ğŸ§ª ä½¿ç”¨å¯¼å…¥çš„å¤šç‰ˆæœ¬æ£€æµ‹å™¨...")
            multi_detector = MultiVersionDetector(self, self.dicom_processor)
            return multi_detector.test_all_preprocessing_versions(dicom_path)
        else:
            # ä½¿ç”¨å•ä¸€é¢„å¤„ç†ç‰ˆæœ¬
            return self._detect_single_version(dicom_path, window_center, window_width)

    def _detect_single_version(self, dicom_path, window_center, window_width):
        """ä½¿ç”¨å•ä¸€é¢„å¤„ç†ç‰ˆæœ¬è¿›è¡Œæ£€æµ‹"""

        # 1. ä½¿ç”¨å¯¼å…¥çš„DICOMé¢„å¤„ç†å™¨
        print("ğŸ”„ ä½¿ç”¨å¯¼å…¥çš„DICOMé¢„å¤„ç†å™¨...")
        processing_result = self.dicom_processor.load_and_preprocess_dicom(
            dicom_path,
            window_center=window_center,
            window_width=window_width
        )

        if processing_result is None:
            return None

        # 2. åˆ›å»ºä¸´æ—¶NIfTIæ–‡ä»¶
        temp_files = self.dicom_processor.save_preprocessing_versions_as_nifti(processing_result)

        # 3. å°è¯•æœ€ä½³ç‰ˆæœ¬
        best_version = 'monai_normalized'
        if best_version in temp_files:
            temp_file = temp_files[best_version]

            try:
                result = self.detect_single_dicom_from_nifti(temp_file)

                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                for temp_f in temp_files.values():
                    try:
                        Path(temp_f).unlink()
                    except:
                        pass

                if result:
                    result['processing_result'] = processing_result
                    result['preprocessing_version'] = best_version

                return result

            except Exception as e:
                print(f"âŒ æ£€æµ‹å¤±è´¥: {e}")
                return None

        return None

    def detect_single_dicom_from_nifti(self, nifti_path):
        """ä»NIfTIæ–‡ä»¶è¿›è¡Œæ£€æµ‹"""
        try:
            # ä½¿ç”¨æœ€å°åŒ–çš„é¢„å¤„ç†
            data_dict = {"image": nifti_path}
            data_dict = self.transforms(data_dict)

            input_tensor = data_dict["image"]

            # ç¡®ä¿å¼ é‡æ ¼å¼æ­£ç¡®
            if input_tensor.dim() == 2:
                input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)
            elif input_tensor.dim() == 3:
                input_tensor = input_tensor.unsqueeze(0)
            elif input_tensor.dim() == 4 and input_tensor.shape[2] == 1:
                # ç§»é™¤å•ä¸€çš„æ·±åº¦ç»´åº¦
                input_tensor = input_tensor.squeeze(2)

            input_tensor = input_tensor.to(self.device)

            print(f"     è¾“å…¥å¼ é‡å½¢çŠ¶: {input_tensor.shape}")
            print(f"     è¾“å…¥èŒƒå›´: [{input_tensor.min():.3f}, {input_tensor.max():.3f}]")

            # æ¨ç†
            self.model.eval()
            with torch.no_grad():
                output = self.model(input_tensor)

                # å¤„ç†è¾“å‡º
                if isinstance(output, dict):
                    return self._process_detection_output(output)
                elif isinstance(output, torch.Tensor):
                    return self._process_segmentation_output(output)
                else:
                    print(f"     æœªçŸ¥è¾“å‡ºç±»å‹: {type(output)}")
                    return None

        except Exception as e:
            print(f"     æ¨ç†å¤±è´¥: {e}")
            return None

    def _process_detection_output(self, output):
        """å¤„ç†ç›®æ ‡æ£€æµ‹è¾“å‡º"""
        try:
            boxes = output.get('boxes', [])
            scores = output.get('scores', [])
            labels = output.get('labels', [])

            print(f"     åŸå§‹æ£€æµ‹æ¡†æ•°é‡: {len(boxes) if hasattr(boxes, '__len__') else 0}")

            if hasattr(boxes, '__len__') and len(boxes) > 0:
                print(f"     ç½®ä¿¡åº¦èŒƒå›´: [{min(scores):.3f}, {max(scores):.3f}]")

                # ä½¿ç”¨æ›´ä½çš„é˜ˆå€¼
                for threshold in [0.1, 0.05, 0.01]:
                    filtered_indices = [i for i, score in enumerate(scores) if score > threshold]

                    if filtered_indices:
                        print(f"     é˜ˆå€¼ {threshold}: {len(filtered_indices)} ä¸ªæ£€æµ‹")

                        return {
                            'detection_mode': True,
                            'boxes': [boxes[i] for i in filtered_indices],
                            'scores': [scores[i] for i in filtered_indices],
                            'labels': [labels[i] for i in filtered_indices] if labels else [],
                            'threshold_used': threshold,
                            'detection_count': len(filtered_indices)
                        }

                # è¿”å›æ‰€æœ‰æ£€æµ‹
                return {
                    'detection_mode': True,
                    'boxes': boxes,
                    'scores': scores,
                    'labels': labels,
                    'threshold_used': 0.0,
                    'detection_count': len(boxes)
                }
            else:
                return {
                    'detection_mode': True,
                    'boxes': [],
                    'scores': [],
                    'labels': [],
                    'threshold_used': 0.0,
                    'detection_count': 0
                }

        except Exception as e:
            print(f"     æ£€æµ‹è¾“å‡ºå¤„ç†å¤±è´¥: {e}")
            return None

    def _process_segmentation_output(self, output):
        """å¤„ç†åˆ†å‰²è¾“å‡º"""
        try:
            print(f"     åˆ†å‰²è¾“å‡ºå½¢çŠ¶: {output.shape}")

            # è·å–æ¦‚ç‡å›¾
            if output.shape[1] > 1:
                probs = torch.softmax(output, dim=1)
                prob_map = probs[0, 1].cpu().numpy()
            else:
                prob_map = torch.sigmoid(output[0, 0]).cpu().numpy()

            print(f"     æ¦‚ç‡å›¾èŒƒå›´: [{prob_map.min():.3f}, {prob_map.max():.3f}]")

            # ä½¿ç”¨å¤šä¸ªé˜ˆå€¼æµ‹è¯•
            thresholds = [0.5, 0.3, 0.1, 0.05]

            for threshold in thresholds:
                binary_mask = prob_map > threshold

                if np.sum(binary_mask) > 0:
                    # è¿é€šç»„ä»¶åˆ†æ
                    labeled_array, num_features = ndimage.label(binary_mask)

                    if num_features > 0:
                        print(f"     é˜ˆå€¼ {threshold}: {num_features} ä¸ªç»„ä»¶")

                        # æå–è¾¹ç•Œæ¡†
                        boxes = []
                        scores = []

                        for i in range(1, num_features + 1):
                            mask = (labeled_array == i)
                            size = np.sum(mask)

                            if size > 10:  # æœ€å°å°ºå¯¸
                                coords = np.where(mask)
                                y1, y2 = coords[0].min(), coords[0].max()
                                x1, x2 = coords[1].min(), coords[1].max()

                                region_probs = prob_map[mask]
                                avg_prob = float(region_probs.mean())

                                boxes.append([int(x1), int(y1), int(x2), int(y2)])
                                scores.append(avg_prob)

                        if boxes:
                            return {
                                'detection_mode': False,
                                'boxes': boxes,
                                'scores': scores,
                                'labels': [1] * len(boxes),
                                'threshold_used': threshold,
                                'detection_count': len(boxes),
                                'probability_map': prob_map
                            }

            # å¦‚æœæ‰€æœ‰é˜ˆå€¼éƒ½æ²¡æœ‰ç»“æœ
            return {
                'detection_mode': False,
                'boxes': [],
                'scores': [],
                'labels': [],
                'threshold_used': 0.5,
                'detection_count': 0,
                'probability_map': prob_map
            }

        except Exception as e:
            print(f"     åˆ†å‰²è¾“å‡ºå¤„ç†å¤±è´¥: {e}")
            return None

    def visualize_improved_result(self, result, save_path=None):
        """å¯è§†åŒ–æ”¹è¿›ç‰ˆæ£€æµ‹ç»“æœ - ä¿®å¤ä¸­æ–‡æ˜¾ç¤º"""
        if not result:
            print("âŒ æ— ç»“æœå¯è§†åŒ–")
            return None

        # ğŸ”§ è®¾ç½®matplotlibä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False

        # å¦‚æœæ˜¯å¤šç‰ˆæœ¬æµ‹è¯•ç»“æœ
        if 'test_results' in result:
            return self._visualize_multi_version_result(result, save_path)

        # å•ç‰ˆæœ¬ç»“æœå¯è§†åŒ–
        if 'processing_result' not in result:
            print("âŒ æ— é¢„å¤„ç†ç»“æœå¯è§†åŒ–")
            return None

        processing_result = result['processing_result']

        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        fig.suptitle('Improved DICOM Detection Results', fontsize=16, fontweight='bold')

        # æ˜¾ç¤ºé¢„å¤„ç†æ­¥éª¤ - ä½¿ç”¨è‹±æ–‡æ ‡é¢˜é¿å…å­—ä½“é—®é¢˜
        axes[0, 0].imshow(processing_result['original_array'], cmap='gray')
        axes[0, 0].set_title('Original DICOM')
        axes[0, 0].axis('off')

        axes[0, 1].imshow(processing_result['enhanced_array'], cmap='gray')
        axes[0, 1].set_title('CLAHE Enhanced')
        axes[0, 1].axis('off')

        axes[0, 2].imshow(processing_result['final_array'], cmap='gray')
        axes[0, 2].set_title('Final Processed')
        axes[0, 2].axis('off')

        # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
        detection_count = result.get('detection_count', 0)
        axes[1, 0].imshow(processing_result['final_array'], cmap='gray')
        axes[1, 0].set_title(f'Detection Results - {detection_count} Candidates')
        axes[1, 0].axis('off')

        # ç»˜åˆ¶æ£€æµ‹æ¡†
        boxes = result.get('boxes', [])
        scores = result.get('scores', [])

        for i, (box, score) in enumerate(zip(boxes, scores)):
            if len(box) == 4:
                x1, y1, x2, y2 = box

                rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,
                                   linewidth=2, edgecolor='red', facecolor='none')
                axes[1, 0].add_patch(rect)

                axes[1, 0].text(x1, y1-5, f'#{i+1}\n{score:.3f}',
                               color='red', fontsize=10, fontweight='bold',
                               bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.8))

        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ - ä½¿ç”¨è‹±æ–‡é¿å…å­—ä½“é—®é¢˜
        stats_text = f"""Detection Statistics:
Candidates: {result.get('detection_count', 0)}
Mode: {'Detection' if result.get('detection_mode', False) else 'Segmentation'}
Threshold: {result.get('threshold_used', 'N/A')}
Version: {result.get('preprocessing_version', 'Default')}

Processing Parameters:
Window Width: {processing_result['preprocessing_info']['window_width']}
Window Center: {processing_result['preprocessing_info']['window_center']}"""

        axes[1, 1].text(0.1, 0.5, stats_text, transform=axes[1, 1].transAxes,
                        fontsize=10, verticalalignment='center',
                        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))
        axes[1, 1].set_title('Detection Statistics')
        axes[1, 1].axis('off')

        # åƒç´ å€¼åˆ†å¸ƒ
        axes[1, 2].hist(processing_result['original_array'].flatten(), bins=50, alpha=0.7, label='Original')
        axes[1, 2].hist(processing_result['final_array'].flatten(), bins=50, alpha=0.7, label='Processed')
        axes[1, 2].set_title('Pixel Distribution')
        axes[1, 2].legend()

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')
            print(f"ğŸ“¸ æ”¹è¿›ç‰ˆæ£€æµ‹ç»“æœä¿å­˜è‡³: {save_path}")

        return fig

    def _visualize_multi_version_result(self, result, save_path=None):
        """å¯è§†åŒ–å¤šç‰ˆæœ¬æµ‹è¯•ç»“æœ - ä¿®å¤ä¸­æ–‡æ˜¾ç¤º"""
        processing_result = result['processing_result']
        test_results = result['test_results']
        best_version = result['best_version']

        # ğŸ”§ è®¾ç½®matplotlibå­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False

        fig, axes = plt.subplots(3, 4, figsize=(20, 15))
        fig.suptitle('Multi-Version Preprocessing Test Results', fontsize=16, fontweight='bold')

        # ç¬¬ä¸€è¡Œï¼šé¢„å¤„ç†æ­¥éª¤ - ä½¿ç”¨è‹±æ–‡æ ‡é¢˜
        axes[0, 0].imshow(processing_result['original_array'], cmap='gray')
        axes[0, 0].set_title('Original DICOM')
        axes[0, 0].axis('off')

        axes[0, 1].imshow(processing_result['windowed_array'], cmap='gray')
        axes[0, 1].set_title('Window Level')
        axes[0, 1].axis('off')

        axes[0, 2].imshow(processing_result['enhanced_array'], cmap='gray')
        axes[0, 2].set_title('CLAHE Enhanced')
        axes[0, 2].axis('off')

        axes[0, 3].imshow(processing_result['final_array'], cmap='gray')
        axes[0, 3].set_title('Final Processing')
        axes[0, 3].axis('off')

        # ç¬¬äºŒè¡Œå’Œç¬¬ä¸‰è¡Œï¼šç‰ˆæœ¬æµ‹è¯•ç»“æœ
        version_names = list(test_results.keys())

        for i, version_name in enumerate(version_names):
            if i >= 8:  # æœ€å¤šæ˜¾ç¤º8ä¸ªç‰ˆæœ¬
                break

            row = 1 + i // 4
            col = i % 4

            test_result = test_results[version_name]

            # æ˜¾ç¤ºç‰ˆæœ¬åå’Œç»“æœ - ä½¿ç”¨è‹±æ–‡å’Œç¬¦å·é¿å…å­—ä½“é—®é¢˜
            title = f"{version_name}\n"
            if test_result['success']:
                title += f"âœ“ {test_result['detection_count']} detections\nConf: {test_result['max_confidence']:.3f}"
                color = 'lightgreen'
            else:
                title += "âœ— No detection"
                color = 'lightcoral'

            axes[row, col].text(0.5, 0.5, title, transform=axes[row, col].transAxes,
                               ha='center', va='center', fontsize=10,
                               bbox=dict(boxstyle='round', facecolor=color, alpha=0.8))
            axes[row, col].set_title(version_name, fontsize=8)
            axes[row, col].axis('off')

        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(version_names), 8):
            row = 1 + i // 4
            col = i % 4
            axes[row, col].axis('off')

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')
            print(f"ğŸ“¸ å¤šç‰ˆæœ¬æµ‹è¯•ç»“æœä¿å­˜è‡³: {save_path}")

        return fig

    def generate_improved_report(self, result, dicom_path):
        """ç”Ÿæˆæ”¹è¿›ç‰ˆæ£€æµ‹æŠ¥å‘Š"""
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        report = f"""
ğŸ¯ Improved Single DICOM Lung Nodule Detection Report
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ‘¤ User: veryjoyran
ğŸ“… Detection Time: {current_time}
ğŸ¤– Model: {self.model_info.get('type', 'Unknown')}
ğŸ“ DICOM File: {Path(dicom_path).name}

ğŸ”§ Improved Features (Using Imported Modules):
  â€¢ Imported DICOM processor from improved_dicom_processor
  â€¢ Reuse of YOLO successful preprocessing modules
  â€¢ Multi-version preprocessing testing via imported MultiVersionDetector
  â€¢ CLAHE contrast enhancement
"""

        # æ ¹æ®ç»“æœç±»å‹ç”Ÿæˆä¸åŒçš„æŠ¥å‘Šå†…å®¹
        if 'test_results' in result:
            # å¤šç‰ˆæœ¬æµ‹è¯•æŠ¥å‘Š
            test_results = result['test_results']
            best_version = result['best_version']

            report += f"""
ğŸ“Š Multi-Version Test Results (via imported MultiVersionDetector):
  â€¢ Tested versions: {len(test_results)}
  â€¢ Best version: {best_version if best_version else 'None'}
  â€¢ Successful versions: {sum(1 for r in test_results.values() if r['success'])}

ğŸ“‹ Version Details:
"""

            for version_name, test_result in test_results.items():
                status = "âœ…" if test_result['success'] else "âŒ"
                count = test_result['detection_count']
                confidence = test_result['max_confidence']

                report += f"""
{status} {version_name}:
  â€¢ Detection count: {count}
  â€¢ Max confidence: {confidence:.3f}
"""
        else:
            # å•ç‰ˆæœ¬æµ‹è¯•æŠ¥å‘Š
            detection_count = result.get('detection_count', 0)
            report += f"""
ğŸ“Š Single Version Detection Results:
  â€¢ Detected candidates: {detection_count}
  â€¢ Detection mode: {'Target Detection' if result.get('detection_mode', False) else 'Segmentation'}
  â€¢ Threshold used: {result.get('threshold_used', 'N/A')}
"""

        report += f"""

âœ… Import Module Advantages:
  â€¢ Clean code architecture with modular design
  â€¢ Reuse of tested and proven DICOM processing logic
  â€¢ Easy maintenance and updates
  â€¢ Separation of concerns

âš™ï¸ Technical Info:
  â€¢ Using imported ImprovedDicomProcessor class
  â€¢ Using imported MultiVersionDetector class
  â€¢ Font display issues resolved with matplotlib configuration
  â€¢ Current user: veryjoyran
  â€¢ Timestamp: 2025-06-24 09:12:56

ğŸ“ Technical Support: veryjoyran | Modular Version: v3.0.0
"""

        return report


# ğŸ”§ åˆ›å»ºç®€åŒ–çš„Gradioæ¥å£é€‚é…å™¨
def create_gradio_compatible_detector():
    """åˆ›å»ºä¸Gradioå…¼å®¹çš„æ£€æµ‹å™¨å®ä¾‹"""
    try:
        print("ğŸ”„ åˆ›å»ºGradioå…¼å®¹çš„æ£€æµ‹å™¨...")
        detector = ImprovedSingleDicomDetector()
        print("âœ… Gradioå…¼å®¹æ£€æµ‹å™¨åˆ›å»ºæˆåŠŸ")
        return detector
    except Exception as e:
        print(f"âŒ Gradioå…¼å®¹æ£€æµ‹å™¨åˆ›å»ºå¤±è´¥: {e}")
        return None


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ğŸš€ ä½¿ç”¨å¯¼å…¥æ¨¡å—çš„DICOMæ£€æµ‹å™¨æµ‹è¯•")
    print(f"ğŸ‘¤ å½“å‰ç”¨æˆ·: veryjoyran")
    print(f"ğŸ“… å½“å‰æ—¶é—´: 2025-06-24 09:12:56")
    print("=" * 60)

    # æµ‹è¯•æ¨¡å—å¯¼å…¥
    try:
        print("ğŸ§ª æµ‹è¯•å¯¼å…¥çš„æ¨¡å—...")
        test_processor = ImprovedDicomProcessor()
        print("âœ… ImprovedDicomProcessorå¯¼å…¥æˆåŠŸ")

        # ç¤ºä¾‹ä½¿ç”¨
        bundle_path = "lung_nodule_ct_detection_v0.5.4.zip"
        dicom_path = "sample.dcm"

        if Path(bundle_path).exists() and Path(dicom_path).exists():
            detector = ImprovedSingleDicomDetector(bundle_path)

            if detector.model is not None:
                result = detector.detect_with_improved_preprocessing(
                    dicom_path,
                    window_center=50,
                    window_width=350,
                    test_all_versions=True
                )

                if result:
                    # å¯è§†åŒ–
                    fig = detector.visualize_improved_result(result, "imported_detection_result.png")

                    # ç”ŸæˆæŠ¥å‘Š
                    report = detector.generate_improved_report(result, dicom_path)
                    print(report)

                    print("âœ… ä½¿ç”¨å¯¼å…¥æ¨¡å—çš„æ£€æµ‹å®Œæˆ!")
                else:
                    print("âŒ æ£€æµ‹å¤±è´¥")
        else:
            print("âŒ è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„")
            print(f"   Bundle: {bundle_path}")
            print(f"   DICOM: {dicom_path}")

    except ImportError as e:
        print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿improved_dicom_processor.pyæ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹")