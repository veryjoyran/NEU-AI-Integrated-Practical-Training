"""
2Dè‚ºç»“èŠ‚æ¨ç†æ£€æµ‹å™¨
Author: veryjoyran
Date: 2025-06-24 03:04:13
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import SimpleITK as sitk
import tempfile
import json
from datetime import datetime

# MonAI 2Dæ¨ç†ç›¸å…³å¯¼å…¥
import monai
from monai.transforms import (
    Compose, LoadImaged, EnsureChannelFirstd, Spacingd,
    Orientationd, ScaleIntensityRanged, ToTensord,
    ResizeWithPadOrCropd, SpatialPadd
)
from scipy import ndimage
from skimage import measure, morphology

# å¯¼å…¥2D BundleåŠ è½½å™¨
from bundle_loader_2D import Bundle2DLoader

print(f"ğŸ”§ MonAIç‰ˆæœ¬: {monai.__version__}")
print(f"ğŸ”§ PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"ğŸ”§ è®¾å¤‡: {'CUDA' if torch.cuda.is_available() else 'CPU'}")


class Inference2DDetector:
    """2Dè‚ºç»“èŠ‚æ¨ç†æ£€æµ‹å™¨"""

    def __init__(self, bundle_path=None, device=None):
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        self.bundle_loader = None
        self.model = None
        self.model_info = {}
        self.is_detection_model = False

        print(f"ğŸš€ åˆå§‹åŒ–2Dæ¨ç†æ£€æµ‹å™¨")
        print(f"   è®¾å¤‡: {self.device}")

        # è®¾ç½®2Dé¢„å¤„ç†å˜æ¢
        self.setup_2d_inference_transforms()

        # å¦‚æœæä¾›äº†bundleè·¯å¾„ï¼Œç«‹å³åŠ è½½
        if bundle_path:
            self.load_bundle_2d(bundle_path)

    def setup_2d_inference_transforms(self):
        """è®¾ç½®2Dæ¨ç†ä¸“ç”¨çš„æ•°æ®é¢„å¤„ç†"""
        print("ğŸ”§ è®¾ç½®2Dæ¨ç†é¢„å¤„ç†æµæ°´çº¿...")

        self.inference_transforms_2d = Compose([
            LoadImaged(keys=["image"]),
            EnsureChannelFirstd(keys=["image"]),
            ScaleIntensityRanged(
                keys=["image"],
                a_min=-1000,
                a_max=400,
                b_min=0.0,
                b_max=1.0,
                clip=True,
            ),
            # 2Dæ ‡å‡†åŒ–å°ºå¯¸
            ResizeWithPadOrCropd(
                keys=["image"],
                spatial_size=(512, 512),
                mode="constant",
                constant_values=0
            ),
            ToTensord(keys=["image"]),
        ])

        print("âœ… 2Dæ¨ç†é¢„å¤„ç†æµæ°´çº¿è®¾ç½®å®Œæˆ")

    def load_bundle_2d(self, bundle_path):
        """åŠ è½½MonAI Bundle - 2Dæ¨¡å¼"""
        try:
            print(f"ğŸ”„ åŠ è½½Bundle (2Dæ¨¡å¼): {bundle_path}")

            self.bundle_loader = Bundle2DLoader(bundle_path, self.device)
            success = self.bundle_loader.load_bundle_for_2d()

            self.model = self.bundle_loader.get_model()
            self.model_info = self.bundle_loader.get_model_info()

            if self.model is None:
                raise Exception("2Dæ¨¡å‹åŠ è½½å¤±è´¥")

            print(f"âœ… 2D BundleåŠ è½½å®Œæˆ")
            print(f"   æ¨¡å‹ç±»å‹: {self.model_info.get('type', 'Unknown')}")
            print(f"   åŸå§‹ç±»å‹: {self.model_info.get('original_type', 'Unknown')}")
            print(f"   é¢„è®­ç»ƒ: {self.model_info.get('pretrained', False)}")
            print(f"   æƒé‡åŠ è½½æ¯”ä¾‹: {self.model_info.get('loaded_ratio', 0):.2f}")
            print(f"   å‚æ•°æ•°é‡: {sum(p.numel() for p in self.model.parameters()):,}")
            print(f"   2Dé€‚é…: {self.model_info.get('adapted_to_2d', False)}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯æ£€æµ‹æ¨¡å‹
            if 'RetinaNet' in self.model_info.get('type', '') or 'RetinaNet' in self.model_info.get('original_type',
                                                                                                    ''):
                print("ğŸ¯ æ£€æµ‹åˆ°RetinaNetæ¨¡å‹ï¼Œå°†ä½¿ç”¨2Dç›®æ ‡æ£€æµ‹æ¨ç†æ¨¡å¼")
                self.is_detection_model = True
            else:
                print("ğŸ¯ æ£€æµ‹åˆ°åˆ†å‰²æ¨¡å‹ï¼Œå°†ä½¿ç”¨2Dåˆ†å‰²æ¨ç†æ¨¡å¼")
                self.is_detection_model = False

            return True

        except Exception as e:
            print(f"âŒ 2D BundleåŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def convert_dicom_to_2d_slices(self, dicom_path):
        """å°†DICOMè½¬æ¢ä¸º2Dåˆ‡ç‰‡"""
        print(f"ğŸ”„ è½¬æ¢DICOMä¸º2Dåˆ‡ç‰‡: {dicom_path}")

        try:
            dicom_path = Path(dicom_path)

            if dicom_path.is_dir():
                # DICOMåºåˆ—ç›®å½•
                reader = sitk.ImageSeriesReader()
                dicom_names = reader.GetGDCMSeriesFileNames(str(dicom_path))

                if not dicom_names:
                    raise ValueError("ç›®å½•ä¸­æœªæ‰¾åˆ°DICOMæ–‡ä»¶")

                reader.SetFileNames(dicom_names)
                image = reader.Execute()
                print(f"   è¯»å–DICOMåºåˆ—: {len(dicom_names)} ä¸ªæ–‡ä»¶")

            elif dicom_path.suffix.lower() == '.dcm':
                # å•ä¸ªDICOMæ–‡ä»¶
                image = sitk.ReadImage(str(dicom_path))
                print(f"   è¯»å–å•ä¸ªDICOMæ–‡ä»¶")
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {dicom_path.suffix}")

            # è·å–åŸºæœ¬ä¿¡æ¯
            print(f"   åŸå§‹å°ºå¯¸: {image.GetSize()}")
            print(f"   ä½“ç´ é—´è·: {[f'{x:.2f}' for x in image.GetSpacing()]}")

            # æ ‡å‡†åŒ–æ–¹å‘
            image = sitk.DICOMOrient(image, 'LPS')

            # è·å–3Dæ•°ç»„
            array_3d = sitk.GetArrayFromImage(image)
            print(f"   HUå€¼èŒƒå›´: [{array_3d.min():.1f}, {array_3d.max():.1f}]")
            print(f"   3Dæ•°ç»„å½¢çŠ¶: {array_3d.shape}")

            # æå–æ‰€æœ‰2Dåˆ‡ç‰‡
            slices_info = []

            for i in range(array_3d.shape[0]):
                slice_2d = array_3d[i]

                # ä¿å­˜ä¸ºä¸´æ—¶NIfTIæ–‡ä»¶
                temp_file = tempfile.mktemp(suffix=f'_slice_{i:03d}.nii.gz')

                # åˆ›å»º2D SimpleITKå›¾åƒ
                image_2d = sitk.GetImageFromArray(slice_2d)
                if len(image.GetSpacing()) >= 2:
                    image_2d.SetSpacing(image.GetSpacing()[:2])

                sitk.WriteImage(image_2d, temp_file)

                slice_info = {
                    'slice_index': i,
                    'array': slice_2d,
                    'temp_file': temp_file,
                    'image_2d': image_2d,
                    'hu_min': float(slice_2d.min()),
                    'hu_max': float(slice_2d.max()),
                    'hu_mean': float(slice_2d.mean()),
                    'shape': slice_2d.shape
                }

                slices_info.append(slice_info)

            print(f"âœ… è½¬æ¢å®Œæˆ: {len(slices_info)} ä¸ª2Dåˆ‡ç‰‡")

            return slices_info, image

        except Exception as e:
            print(f"âŒ DICOMè½¬æ¢å¤±è´¥: {e}")
            return None, None

    def inference_2d_single_slice(self, nifti_path_2d):
        """å¯¹å•ä¸ª2Dåˆ‡ç‰‡è¿›è¡Œæ¨ç†"""
        if self.model is None:
            print("âŒ æ¨¡å‹æœªåŠ è½½")
            return None

        print(f"ğŸ” å¼€å§‹2Då•åˆ‡ç‰‡æ¨ç†")
        print(f"   è¾“å…¥: {Path(nifti_path_2d).name}")

        try:
            # å‡†å¤‡æ•°æ®
            data_dict = {"image": nifti_path_2d}

            # åº”ç”¨é¢„å¤„ç†
            data_dict = self.inference_transforms_2d(data_dict)

            # è·å–å¤„ç†åçš„å¼ é‡
            input_tensor = data_dict["image"]
            print(f"   é¢„å¤„ç†åå½¢çŠ¶: {input_tensor.shape}")

            # ç¡®ä¿æœ‰æ‰¹æ¬¡ç»´åº¦
            if input_tensor.dim() == 2:  # (H, W)
                input_tensor = input_tensor.unsqueeze(0).unsqueeze(0)  # (1, 1, H, W)
            elif input_tensor.dim() == 3:  # (C, H, W)
                input_tensor = input_tensor.unsqueeze(0)  # (1, C, H, W)

            input_tensor = input_tensor.to(self.device)
            print(f"   æœ€ç»ˆè¾“å…¥å½¢çŠ¶: {input_tensor.shape}")

            # ğŸ”¥ æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©æ¨ç†æ–¹æ³•
            if self.is_detection_model:
                return self._detection_inference_2d(input_tensor)
            else:
                return self._segmentation_inference_2d(input_tensor)

        except Exception as e:
            print(f"âŒ 2Dæ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _detection_inference_2d(self, input_tensor):
        """2Dç›®æ ‡æ£€æµ‹æ¨ç†"""
        print(f"   æ‰§è¡Œ2Dç›®æ ‡æ£€æµ‹æ¨ç†...")

        try:
            self.model.eval()
            with torch.no_grad():

                print(f"   ğŸ” 2Dæ£€æµ‹è¯¦ç»†ä¿¡æ¯:")
                print(f"     è¾“å…¥å¼ é‡å°ºå¯¸: {input_tensor.shape}")
                print(f"     è¾“å…¥æ•°æ®ç±»å‹: {input_tensor.dtype}")
                print(f"     è¾“å…¥èŒƒå›´: [{input_tensor.min():.3f}, {input_tensor.max():.3f}]")

                # ç›´æ¥è°ƒç”¨æ¨¡å‹
                output = self.model(input_tensor)

                print(f"     è¾“å‡ºç±»å‹: {type(output)}")

                if isinstance(output, dict):
                    print("     è¾“å‡ºæ˜¯å­—å…¸æ ¼å¼:")
                    for key, value in output.items():
                        if isinstance(value, torch.Tensor):
                            print(f"       {key}: å½¢çŠ¶={value.shape}")
                            if value.numel() > 0:
                                print(f"             èŒƒå›´=[{value.min():.3f}, {value.max():.3f}]")
                        elif isinstance(value, list):
                            print(f"       {key}: åˆ—è¡¨é•¿åº¦={len(value)}")
                        else:
                            print(f"       {key}: {type(value)}")

                    boxes = output.get('boxes', [])
                    scores = output.get('scores', [])
                    labels = output.get('labels', [])

                    print(f"     æ£€æµ‹ç»“æœ:")
                    print(f"       æ£€æµ‹æ¡†æ•°é‡: {len(boxes) if hasattr(boxes, '__len__') else 0}")

                    if hasattr(boxes, '__len__') and len(boxes) > 0:
                        print(f"       ğŸ¯ å‘ç°æ£€æµ‹æ¡†!")

                        # åº”ç”¨å¤šä¸ªé˜ˆå€¼
                        thresholds = [0.5, 0.3, 0.1, 0.05]

                        for threshold in thresholds:
                            high_conf_indices = [i for i, score in enumerate(scores) if score > threshold]

                            if high_conf_indices:
                                filtered_boxes = [boxes[i] for i in high_conf_indices]
                                filtered_scores = [scores[i] for i in high_conf_indices]
                                filtered_labels = [labels[i] for i in high_conf_indices] if labels else []

                                print(f"       é˜ˆå€¼ {threshold}: {len(filtered_boxes)} ä¸ªæ£€æµ‹")

                                if threshold <= 0.3:  # ä½¿ç”¨è¾ƒä½çš„é˜ˆå€¼
                                    return {
                                        'boxes': filtered_boxes,
                                        'scores': filtered_scores,
                                        'labels': filtered_labels,
                                        'input_shape': input_tensor.shape,
                                        'detection_count': len(filtered_boxes),
                                        'detection_mode': True,
                                        'threshold_used': threshold
                                    }

                        # å¦‚æœæ‰€æœ‰é˜ˆå€¼éƒ½æ²¡æœ‰ç»“æœï¼Œä½¿ç”¨æä½é˜ˆå€¼
                        print(f"       ä½¿ç”¨æ‰€æœ‰æ£€æµ‹ç»“æœ (æ— é˜ˆå€¼è¿‡æ»¤)")
                        return {
                            'boxes': boxes,
                            'scores': scores,
                            'labels': labels,
                            'input_shape': input_tensor.shape,
                            'detection_count': len(boxes),
                            'detection_mode': True,
                            'threshold_used': 0.0
                        }

                    else:
                        print(f"       âŒ æœªæ£€æµ‹åˆ°ä»»ä½•ç›®æ ‡")
                        return {
                            'boxes': [],
                            'scores': [],
                            'labels': [],
                            'input_shape': input_tensor.shape,
                            'detection_count': 0,
                            'detection_mode': True,
                            'threshold_used': 0.0
                        }

                # å¤„ç†å…¶ä»–è¾“å‡ºæ ¼å¼
                elif isinstance(output, torch.Tensor):
                    print(f"     ç›´æ¥å¼ é‡è¾“å‡ºï¼Œå°è¯•ä½œä¸ºåˆ†å‰²ç»“æœå¤„ç†")
                    return self._process_segmentation_output_2d(output, input_tensor)

                else:
                    print(f"     æœªçŸ¥è¾“å‡ºæ ¼å¼: {type(output)}")
                    return None

        except Exception as e:
            print(f"âš ï¸ 2Dç›®æ ‡æ£€æµ‹æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _segmentation_inference_2d(self, input_tensor):
        """2Dè¯­ä¹‰åˆ†å‰²æ¨ç†"""
        print(f"   æ‰§è¡Œ2Dè¯­ä¹‰åˆ†å‰²æ¨ç†...")

        try:
            self.model.eval()
            with torch.no_grad():

                # ç›´æ¥æ¨ç†
                output = self.model(input_tensor)

                print(f"   åŸå§‹æ¨ç†è¾“å‡ºå½¢çŠ¶: {output.shape}")

                return self._process_segmentation_output_2d(output, input_tensor)

        except Exception as e:
            print(f"âš ï¸ 2Dåˆ†å‰²æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _process_segmentation_output_2d(self, output, input_tensor):
        """å¤„ç†2Dåˆ†å‰²è¾“å‡º"""
        try:
            # åº”ç”¨softmaxè·å–æ¦‚ç‡
            if output.shape[1] > 1:  # å¤šç±»è¾“å‡º
                probs = torch.softmax(output, dim=1)
                prob_map = probs[0, 1].cpu().numpy()  # ç»“èŠ‚æ¦‚ç‡
            else:
                prob_map = torch.sigmoid(output[0, 0]).cpu().numpy()

            print(f"   æ¦‚ç‡å›¾ç»Ÿè®¡: min={prob_map.min():.3f}, max={prob_map.max():.3f}, mean={prob_map.mean():.3f}")

            # åº”ç”¨é˜ˆå€¼
            threshold = 0.5
            binary_mask = prob_map > threshold

            print(f"   é˜ˆå€¼({threshold})åé˜³æ€§åƒç´ : {np.sum(binary_mask)}")

            # å½¢æ€å­¦å¤„ç†
            if np.sum(binary_mask) > 0:
                # 2Då½¢æ€å­¦å¼€è¿ç®—
                kernel = morphology.disk(2)
                binary_mask = morphology.binary_opening(binary_mask, kernel)
                print(f"   å½¢æ€å­¦å¼€è¿ç®—åé˜³æ€§åƒç´ : {np.sum(binary_mask)}")

                # 2Då½¢æ€å­¦é—­è¿ç®—
                kernel = morphology.disk(1)
                binary_mask = morphology.binary_closing(binary_mask, kernel)
                print(f"   å½¢æ€å­¦é—­è¿ç®—åé˜³æ€§åƒç´ : {np.sum(binary_mask)}")

            # è¿é€šç»„ä»¶åˆ†æ
            labeled_array, num_features = ndimage.label(binary_mask)
            print(f"   è¿é€šç»„ä»¶æ•°é‡: {num_features}")

            # æå–è¾¹ç•Œæ¡†
            boxes = []
            scores = []
            labels = []

            for i in range(1, num_features + 1):
                mask = (labeled_array == i)
                size = np.sum(mask)

                if size > 10:  # æœ€å°å°ºå¯¸
                    # è®¡ç®—è¾¹ç•Œæ¡†
                    coords = np.where(mask)
                    y1, y2 = coords[0].min(), coords[0].max()
                    x1, x2 = coords[1].min(), coords[1].max()

                    # è®¡ç®—å¹³å‡æ¦‚ç‡ä½œä¸ºç½®ä¿¡åº¦
                    region_probs = prob_map[mask]
                    avg_prob = float(region_probs.mean())

                    if avg_prob > 0.3:  # æ¦‚ç‡é˜ˆå€¼
                        boxes.append([int(x1), int(y1), int(x2), int(y2)])
                        scores.append(avg_prob)
                        labels.append(1)

            print(f"âœ… 2Dåˆ†å‰²æ¨ç†å®Œæˆï¼Œæå–åˆ° {len(boxes)} ä¸ªå€™é€‰åŒºåŸŸ")

            return {
                'boxes': boxes,
                'scores': scores,
                'labels': labels,
                'input_shape': input_tensor.shape,
                'detection_count': len(boxes),
                'detection_mode': False,  # åˆ†å‰²æ¨¡å¼
                'probability_map': prob_map,
                'binary_mask': binary_mask
            }

        except Exception as e:
            print(f"âŒ 2Dåˆ†å‰²è¾“å‡ºå¤„ç†å¤±è´¥: {e}")
            return None

    def batch_inference_all_slices(self, dicom_path, confidence_threshold=0.3, max_slices=None):
        """æ‰¹é‡æ¨ç†æ‰€æœ‰2Dåˆ‡ç‰‡"""
        print(f"ğŸ” æ‰¹é‡2Dæ¨ç†æ‰€æœ‰åˆ‡ç‰‡")

        # è½¬æ¢ä¸º2Dåˆ‡ç‰‡
        slices_info, original_image = self.convert_dicom_to_2d_slices(dicom_path)

        if not slices_info:
            return None

        # é™åˆ¶å¤„ç†çš„åˆ‡ç‰‡æ•°é‡ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        if max_slices:
            slices_info = slices_info[:max_slices]
            print(f"   é™åˆ¶å¤„ç†åˆ‡ç‰‡æ•°é‡: {max_slices}")

        all_detections = []
        total_slices = len(slices_info)

        print(f"   å¼€å§‹é€åˆ‡ç‰‡æ¨ç† ({total_slices} ä¸ªåˆ‡ç‰‡)...")

        for i, slice_info in enumerate(slices_info):
            print(f"   å¤„ç†åˆ‡ç‰‡ {i + 1}/{total_slices} (ç´¢å¼•: {slice_info['slice_index']})")

            # æ¨ç†å•ä¸ªåˆ‡ç‰‡
            inference_result = self.inference_2d_single_slice(slice_info['temp_file'])

            if inference_result and inference_result['detection_count'] > 0:
                # è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹
                boxes = inference_result['boxes']
                scores = inference_result['scores']
                labels = inference_result['labels']

                high_conf_indices = [j for j, score in enumerate(scores) if score > confidence_threshold]

                if high_conf_indices:
                    filtered_result = {
                        'slice_index': slice_info['slice_index'],
                        'slice_array': slice_info['array'],
                        'boxes': [boxes[j] for j in high_conf_indices],
                        'scores': [scores[j] for j in high_conf_indices],
                        'labels': [labels[j] for j in high_conf_indices] if labels else [],
                        'detection_count': len(high_conf_indices),
                        'detection_mode': inference_result.get('detection_mode', False),
                        'threshold_used': inference_result.get('threshold_used', confidence_threshold),
                        'hu_stats': {
                            'min': slice_info['hu_min'],
                            'max': slice_info['hu_max'],
                            'mean': slice_info['hu_mean']
                        }
                    }

                    # å¦‚æœæ˜¯åˆ†å‰²æ¨¡å¼ï¼Œä¿å­˜æ¦‚ç‡å›¾
                    if 'probability_map' in inference_result:
                        filtered_result['probability_map'] = inference_result['probability_map']
                    if 'binary_mask' in inference_result:
                        filtered_result['binary_mask'] = inference_result['binary_mask']

                    all_detections.append(filtered_result)

                    print(f"     âœ… åˆ‡ç‰‡ {i + 1} æ£€æµ‹åˆ° {len(high_conf_indices)} ä¸ªé«˜ç½®ä¿¡åº¦å€™é€‰")
                else:
                    print(f"     â– åˆ‡ç‰‡ {i + 1} æœ‰æ£€æµ‹ä½†ç½®ä¿¡åº¦è¿‡ä½")
            else:
                print(f"     â– åˆ‡ç‰‡ {i + 1} æ— æ£€æµ‹ç»“æœ")

        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        for slice_info in slices_info:
            try:
                Path(slice_info['temp_file']).unlink()
            except:
                pass

        print(f"âœ… æ‰¹é‡2Dæ¨ç†å®Œæˆ")
        print(f"   æœ‰æ£€æµ‹ç»“æœçš„åˆ‡ç‰‡: {len(all_detections)}/{total_slices}")

        if all_detections:
            total_detections = sum(d['detection_count'] for d in all_detections)
            max_confidence = max(max(d['scores']) for d in all_detections)
            avg_confidence = np.mean([score for d in all_detections for score in d['scores']])

            print(f"   æ€»æ£€æµ‹æ•°é‡: {total_detections}")
            print(f"   æœ€é«˜ç½®ä¿¡åº¦: {max_confidence:.3f}")
            print(f"   å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")

        return all_detections

    def extract_candidates_2d(self, detection_results, min_confidence=0.3):
        """ä»2Dæ£€æµ‹ç»“æœä¸­æå–å€™é€‰ç»“èŠ‚"""
        print(f"ğŸ¯ æå–2Då€™é€‰ç»“èŠ‚")
        print(f"   æœ€å°ç½®ä¿¡åº¦: {min_confidence}")

        if not detection_results:
            print("   æ— æ£€æµ‹ç»“æœ")
            return []

        candidates = []
        candidate_id = 1

        for slice_result in detection_results:
            slice_idx = slice_result['slice_index']
            boxes = slice_result['boxes']
            scores = slice_result['scores']

            for box, score in zip(boxes, scores):
                if score >= min_confidence:
                    x1, y1, x2, y2 = box

                    candidate = {
                        "id": candidate_id,
                        "slice_index": slice_idx,
                        "bbox_2d": [x1, y1, x2, y2],
                        "center_2d": [(x1 + x2) / 2, (y1 + y2) / 2],
                        "size_2d": (x2 - x1) * (y2 - y1),
                        "confidence": score,
                        "detection_mode": slice_result.get('detection_mode', False)
                    }

                    candidates.append(candidate)
                    candidate_id += 1

        # æŒ‰ç½®ä¿¡åº¦æ’åº
        candidates = sorted(candidates, key=lambda x: x["confidence"], reverse=True)

        print(f"âœ… æå–åˆ° {len(candidates)} ä¸ª2Då€™é€‰ç»“èŠ‚")

        # æ˜¾ç¤ºå‰å‡ ä¸ªå€™é€‰
        for i, cand in enumerate(candidates[:5]):
            print(
                f"   å€™é€‰ {i + 1}: åˆ‡ç‰‡#{cand['slice_index']}, ç½®ä¿¡åº¦={cand['confidence']:.3f}, å°ºå¯¸={cand['size_2d']:.0f}")

        return candidates


# 2Då¯è§†åŒ–å™¨
class Simple2DVisualizer:
    """ç®€å•çš„2Dç»“æœå¯è§†åŒ–å™¨"""

    @staticmethod
    def create_2d_detection_overview(detection_results, save_path=None):
        """åˆ›å»º2Dæ£€æµ‹ç»“æœæ€»è§ˆ"""

        if not detection_results:
            print("âŒ æ— æ£€æµ‹ç»“æœå¯è§†åŒ–")
            return None

        # é€‰æ‹©æœ€ä½³çš„æ£€æµ‹ç»“æœè¿›è¡Œå±•ç¤º
        sorted_results = sorted(detection_results,
                                key=lambda x: max(x['scores']) if x['scores'] else 0,
                                reverse=True)

        # æœ€å¤šæ˜¾ç¤º8ä¸ªæœ€ä½³åˆ‡ç‰‡
        top_results = sorted_results[:8]

        cols = 4
        rows = 2
        fig, axes = plt.subplots(rows, cols, figsize=(20, 10))
        fig.suptitle(f'2Dè‚ºç»“èŠ‚æ£€æµ‹æ€»è§ˆ - {len(detection_results)}ä¸ªåˆ‡ç‰‡æœ‰æ£€æµ‹ç»“æœ',
                     fontsize=16, fontweight='bold')

        for i, result in enumerate(top_results):
            if i >= rows * cols:
                break

            row = i // cols
            col = i % cols
            ax = axes[row, col]

            slice_array = result['slice_array']
            slice_idx = result['slice_index']

            # æ˜¾ç¤ºåˆ‡ç‰‡
            ax.imshow(slice_array, cmap='gray', vmin=slice_array.min(), vmax=slice_array.max())
            ax.set_title(f'åˆ‡ç‰‡ #{slice_idx} - {result["detection_count"]} ä¸ªæ£€æµ‹')
            ax.axis('off')

            # ç»˜åˆ¶æ£€æµ‹æ¡†
            boxes = result['boxes']
            scores = result['scores']

            for j, (box, score) in enumerate(zip(boxes, scores)):
                x1, y1, x2, y2 = box

                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                rect = plt.Rectangle((x1, y1), x2 - x1, y2 - y1,
                                     linewidth=2, edgecolor='red', facecolor='none')
                ax.add_patch(rect)

                # æ·»åŠ æ ‡ç­¾
                ax.text(x1, y1 - 3, f'#{j + 1}\n{score:.2f}',
                        color='red', fontsize=8, fontweight='bold',
                        bbox=dict(boxstyle='round,pad=0.2', facecolor='yellow', alpha=0.8))

        # éšè—å¤šä½™çš„å­å›¾
        for i in range(len(top_results), rows * cols):
            row = i // cols
            col = i % cols
            axes[row, col].axis('off')

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')
            print(f"ğŸ“¸ 2Dæ£€æµ‹æ€»è§ˆä¿å­˜è‡³: {save_path}")

        return fig

    @staticmethod
    def create_2d_candidates_montage(candidates, detection_results, save_path=None):
        """åˆ›å»º2Då€™é€‰ç»“èŠ‚è’™å¤ªå¥‡"""

        if not candidates:
            print("âŒ æ— 2Då€™é€‰ç»“èŠ‚å¯è§†åŒ–")
            return None

        # ä¸ºå€™é€‰ç»“èŠ‚æ‰¾åˆ°å¯¹åº”çš„åˆ‡ç‰‡æ•°æ®
        slice_data_map = {r['slice_index']: r['slice_array'] for r in detection_results}

        n_candidates = min(len(candidates), 12)  # æœ€å¤šæ˜¾ç¤º12ä¸ªå€™é€‰

        cols = 4
        rows = (n_candidates + cols - 1) // cols

        fig, axes = plt.subplots(rows, cols, figsize=(16, 4 * rows))
        if rows == 1:
            axes = axes.reshape(1, -1)

        fig.suptitle(f'2Då€™é€‰ç»“èŠ‚è¯¦ç»†è§†å›¾ (å‰{n_candidates}ä¸ª)', fontsize=16, fontweight='bold')

        for i in range(n_candidates):
            row = i // cols
            col = i % cols
            ax = axes[row, col]

            cand = candidates[i]
            slice_idx = cand['slice_index']

            if slice_idx in slice_data_map:
                slice_array = slice_data_map[slice_idx]
                x1, y1, x2, y2 = cand['bbox_2d']

                # æå–å€™é€‰åŒºåŸŸçš„patch
                patch_size = 64
                center_x, center_y = cand['center_2d']

                patch_x1 = max(0, int(center_x - patch_size // 2))
                patch_x2 = min(slice_array.shape[1], int(center_x + patch_size // 2))
                patch_y1 = max(0, int(center_y - patch_size // 2))
                patch_y2 = min(slice_array.shape[0], int(center_y + patch_size // 2))

                patch = slice_array[patch_y1:patch_y2, patch_x1:patch_x2]

                # æ˜¾ç¤ºpatch
                ax.imshow(patch, cmap='gray')
                ax.set_title(f'å€™é€‰#{cand["id"]} (åˆ‡ç‰‡#{slice_idx})\nç½®ä¿¡åº¦:{cand["confidence"]:.3f}', fontsize=10)
                ax.axis('off')

                # åœ¨patchä¸­å¿ƒç”»åå­—
                h, w = patch.shape
                ax.plot([w // 2 - 5, w // 2 + 5], [h // 2, h // 2], 'r-', linewidth=2)
                ax.plot([w // 2, w // 2], [h // 2 - 5, h // 2 + 5], 'r-', linewidth=2)
            else:
                ax.text(0.5, 0.5, f'å€™é€‰#{cand["id"]}\nåˆ‡ç‰‡#{slice_idx}\næ•°æ®ç¼ºå¤±',
                        transform=ax.transAxes, ha='center', va='center')
                ax.axis('off')

        # éšè—å¤šä½™çš„å­å›¾
        for i in range(n_candidates, rows * cols):
            row = i // cols
            col = i % cols
            axes[row, col].axis('off')

        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight', facecolor='white')
            print(f"ğŸ“¸ 2Då€™é€‰è’™å¤ªå¥‡ä¿å­˜è‡³: {save_path}")

        return fig


def save_2d_inference_results(candidates, detection_results, model_info, output_dir="./2d_inference_results"):
    """ä¿å­˜2Dæ¨ç†ç»“æœ"""
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    results_data = {
        "user": "veryjoyran",
        "timestamp": timestamp,
        "inference_date": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "version": "2d_inference_v1.0.0",
        "mode": "2d_slice_by_slice",
        "model_info": model_info,
        "summary": {
            "total_slices_with_detections": len(detection_results),
            "total_candidates": len(candidates),
            "total_detections": sum(d['detection_count'] for d in detection_results),
            "max_confidence": max([max(d['scores']) for d in detection_results]) if detection_results else 0,
            "avg_confidence": np.mean(
                [score for d in detection_results for score in d['scores']]) if detection_results else 0
        },
        "candidates": candidates,
        "detection_results": [
            {
                "slice_index": d["slice_index"],
                "detection_count": d["detection_count"],
                "boxes": d["boxes"],
                "scores": d["scores"],
                "detection_mode": d.get("detection_mode", False),
                "hu_stats": d.get("hu_stats", {})
            }
            for d in detection_results
        ]
    }

    json_path = output_path / f"2d_inference_results_{timestamp}.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(results_data, f, indent=2, ensure_ascii=False, default=str)

    print(f"ğŸ’¾ 2Dæ¨ç†ç»“æœä¿å­˜è‡³: {json_path}")
    return json_path


def run_2d_inference(bundle_path, dicom_path, output_dir="./2d_inference_results"):
    """è¿è¡Œå®Œæ•´çš„2Dæ¨ç†æµç¨‹"""
    print("ğŸš€ å¼€å§‹2Dè‚ºç»“èŠ‚æ£€æµ‹æ¨ç†")
    print(f"ğŸ‘¤ ç”¨æˆ·: veryjoyran")
    print(f"ğŸ“… æ—¶é—´: 2025-01-24 03:10:12")
    print("=" * 60)

    try:
        # 1. åˆå§‹åŒ–2Dæ£€æµ‹å™¨
        print("\nğŸ“‹ ç¬¬1æ­¥: åˆå§‹åŒ–2Dæ£€æµ‹å™¨")
        detector = Inference2DDetector(bundle_path)

        if detector.model is None:
            print("âŒ 2Dæ£€æµ‹å™¨åˆå§‹åŒ–å¤±è´¥")
            return None

        # 2. æ‰¹é‡æ¨ç†æ‰€æœ‰åˆ‡ç‰‡
        print("\nğŸ“‹ ç¬¬2æ­¥: æ‰¹é‡æ¨ç†æ‰€æœ‰2Dåˆ‡ç‰‡")
        detection_results = detector.batch_inference_all_slices(
            dicom_path,
            confidence_threshold=0.3,
            max_slices=None  # å¤„ç†æ‰€æœ‰åˆ‡ç‰‡
        )

        if not detection_results:
            print("âŒ æ‰€æœ‰åˆ‡ç‰‡éƒ½æ— æ£€æµ‹ç»“æœ")
            return None

        # 3. æå–å€™é€‰ç»“èŠ‚
        print("\nğŸ“‹ ç¬¬3æ­¥: æå–2Då€™é€‰ç»“èŠ‚")
        candidates = detector.extract_candidates_2d(detection_results, min_confidence=0.3)

        if not candidates:
            print("âŒ æœªæå–åˆ°æœ‰æ•ˆå€™é€‰ç»“èŠ‚")
            return None

        # 4. ç”Ÿæˆå¯è§†åŒ–
        print("\nğŸ“‹ ç¬¬4æ­¥: ç”Ÿæˆ2Då¯è§†åŒ–")
        visualizer = Simple2DVisualizer()

        # åˆ›å»ºæ£€æµ‹æ€»è§ˆ
        overview_fig = visualizer.create_2d_detection_overview(
            detection_results,
            save_path=Path(output_dir) / "2d_detection_overview.png"
        )

        # åˆ›å»ºå€™é€‰è’™å¤ªå¥‡
        montage_fig = visualizer.create_2d_candidates_montage(
            candidates,
            detection_results,
            save_path=Path(output_dir) / "2d_candidates_montage.png"
        )

        # 5. ä¿å­˜ç»“æœ
        print("\nğŸ“‹ ç¬¬5æ­¥: ä¿å­˜2Dæ¨ç†ç»“æœ")
        json_path = save_2d_inference_results(
            candidates,
            detection_results,
            detector.model_info,
            output_dir
        )

        print(f"\nğŸ‰ 2Dæ¨ç†å®Œæˆ!")
        print(f"   æœ‰æ£€æµ‹ç»“æœçš„åˆ‡ç‰‡: {len(detection_results)}")
        print(f"   å€™é€‰ç»“èŠ‚æ•°é‡: {len(candidates)}")
        print(f"   æœ€é«˜ç½®ä¿¡åº¦: {max(c['confidence'] for c in candidates):.3f}")
        print(f"   ç»“æœä¿å­˜ç›®å½•: {output_dir}")

        return {
            "detector": detector,
            "detection_results": detection_results,
            "candidates": candidates,
            "json_path": json_path,
            "overview_fig": overview_fig,
            "montage_fig": montage_fig
        }

    except Exception as e:
        print(f"âŒ 2Dæ¨ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


if __name__ == "__main__":
    # ä½¿ç”¨ç¤ºä¾‹
    bundle_path = "lung_nodule_ct_detection_v0.5.9.zip"
    dicom_path = "path/to/your/dicom/data"

    if Path(bundle_path).exists() and Path(dicom_path).exists():
        result = run_2d_inference(bundle_path, dicom_path)

        if result:
            print("âœ… 2Dæ¨ç†æˆåŠŸå®Œæˆ!")
        else:
            print("âŒ 2Dæ¨ç†å¤±è´¥")
    else:
        print("âŒ è¯·æ£€æŸ¥Bundleå’ŒDICOMè·¯å¾„")