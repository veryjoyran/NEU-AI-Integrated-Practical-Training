import torch
import json
import yaml
from pathlib import Path
from monai.bundle import ConfigParser
from monai.networks.nets import BasicUNet
import zipfile
import tempfile
import warnings

class MonAIBundleLoader:
    """MonAI BundleåŠ è½½å™¨ - ä¸“é—¨ç”¨äºLUNA16è‚ºç»“èŠ‚æ£€æµ‹"""

    def __init__(self, bundle_path, device='cpu'):
        self.bundle_path = Path(bundle_path)
        self.device = device
        self.model = None
        self.config = None
        self.model_info = {}
        self.bundle_dir = None

        print(f"ğŸš€ åˆå§‹åŒ–MonAI BundleåŠ è½½å™¨")
        print(f"   Bundleè·¯å¾„: {self.bundle_path}")
        print(f"   è®¾å¤‡: {self.device}")
        print(f"   å½“å‰ç”¨æˆ·: veryjoyran")
        print(f"   æ—¶é—´: 2025-06-24 15:25:42")

    def load_bundle(self):
        """åŠ è½½MonAI Bundle"""
        print(f"ğŸ”„ å¼€å§‹åŠ è½½Bundle: {self.bundle_path}")

        try:
            # 1. è§£å‹Bundleï¼ˆå¦‚æœæ˜¯ZIPæ–‡ä»¶ï¼‰
            if self.bundle_path.suffix.lower() == '.zip':
                self.bundle_dir = self._extract_bundle_zip()
            else:
                self.bundle_dir = self.bundle_path

            print(f"   Bundleç›®å½•: {self.bundle_dir}")

            # 2. æŸ¥æ‰¾å¹¶åŠ è½½é…ç½®æ–‡ä»¶
            config_file = self._find_config_file()
            if not config_file:
                raise FileNotFoundError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„é…ç½®æ–‡ä»¶")

            print(f"   æ‰¾åˆ°é…ç½®æ–‡ä»¶: {config_file.name}")

            # 3. ä½¿ç”¨ConfigParseråŠ è½½æ¨¡å‹
            success = self._load_model_with_config_parser(config_file)

            if not success:
                print("   ConfigParseråŠ è½½å¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨åˆ›å»ºæ¨¡å‹...")
                self._load_config_manually(config_file)
                self.model = self._create_fallback_model()
                self._load_weights_manually()

            # 4. éªŒè¯æ¨¡å‹
            self._validate_model()

            print("âœ… BundleåŠ è½½å®Œæˆ")
            self._print_model_info()

            return True

        except Exception as e:
            print(f"âŒ BundleåŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            # å°è¯•åˆ›å»ºå¤‡ç”¨æ¨¡å‹
            print("ğŸ”„ å°è¯•åˆ›å»ºå¤‡ç”¨æ¨¡å‹...")
            self.model = self._create_fallback_model()
            return False

    def _extract_bundle_zip(self):
        """è§£å‹Bundle ZIPæ–‡ä»¶"""
        print("   è§£å‹Bundle ZIPæ–‡ä»¶...")
        extract_dir = Path(tempfile.mkdtemp(prefix="monai_bundle_"))

        try:
            with zipfile.ZipFile(self.bundle_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)

            # æŸ¥æ‰¾å®é™…çš„Bundleç›®å½•
            bundle_dirs = [d for d in extract_dir.iterdir() if d.is_dir()]
            if bundle_dirs:
                actual_bundle_dir = bundle_dirs[0]
                print(f"   è§£å‹å®Œæˆ: {actual_bundle_dir}")
                return actual_bundle_dir
            else:
                print(f"   è§£å‹å®Œæˆ: {extract_dir}")
                return extract_dir

        except Exception as e:
            print(f"   è§£å‹å¤±è´¥: {e}")
            raise

    def _find_config_file(self):
        """æŸ¥æ‰¾é…ç½®æ–‡ä»¶"""
        print("   æŸ¥æ‰¾é…ç½®æ–‡ä»¶...")

        # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾é…ç½®æ–‡ä»¶
        config_patterns = [
            "configs/inference.json",
            "configs/inference.yaml",
            "configs/train.json",
            "configs/train.yaml",
            "inference.json",
            "train.json",
            "**/inference*.json",
            "**/train*.json"
        ]

        for pattern in config_patterns:
            config_files = list(self.bundle_dir.glob(pattern))
            if config_files:
                config_file = config_files[0]
                print(f"   æ‰¾åˆ°é…ç½®æ–‡ä»¶: {pattern} -> {config_file.name}")
                return config_file

        print("   âš ï¸ æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶")
        return None

    def _load_model_with_config_parser(self, config_file):
        """ä½¿ç”¨ConfigParseråŠ è½½æ¨¡å‹"""
        print("   ä½¿ç”¨ConfigParseråŠ è½½æ¨¡å‹...")

        try:
            # åˆå§‹åŒ–ConfigParser
            self.parser = ConfigParser()
            self.parser.read_config(str(config_file))

            print(f"   é…ç½®æ–‡ä»¶è§£ææˆåŠŸï¼ŒåŒ…å« {len(self.parser.config)} ä¸ªé¡¶çº§é”®")

            # æŸ¥æ‰¾ç½‘ç»œå®šä¹‰
            network_keys = ['network_def', 'network', 'model', 'detector']
            network_config = None

            for key in network_keys:
                if key in self.parser.config:
                    try:
                        print(f"   å°è¯•è§£æç½‘ç»œé…ç½®é”®: {key}")
                        network_config = self.parser.get_parsed_content(key)
                        print(f"   æˆåŠŸè§£æç½‘ç»œ: {type(network_config)}")
                        break
                    except Exception as e:
                        print(f"   è§£æé”® {key} å¤±è´¥: {e}")
                        continue

            if network_config is None:
                print("   âš ï¸ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç½‘ç»œé…ç½®")
                return False

            self.model = network_config

            # å°è¯•åŠ è½½æƒé‡ï¼ˆé€šè¿‡initializeé…ç½®ï¼‰
            if 'initialize' in self.parser.config:
                try:
                    print("   æ‰§è¡ŒBundleåˆå§‹åŒ–...")
                    initializer = self.parser.get_parsed_content('initialize')
                    if hasattr(initializer, '__call__'):
                        initializer()
                        print("   Bundleåˆå§‹åŒ–å®Œæˆ")
                    self.model_info['weights_loaded'] = True
                except Exception as e:
                    print(f"   Bundleåˆå§‹åŒ–å¤±è´¥: {e}")
                    self.model_info['weights_loaded'] = False
                    # å°è¯•æ‰‹åŠ¨åŠ è½½æƒé‡
                    self._load_weights_manually()
            else:
                print("   æ— initializeé…ç½®ï¼Œå°è¯•æ‰‹åŠ¨åŠ è½½æƒé‡...")
                self._load_weights_manually()

            # è®¾ç½®æ¨¡å‹ä¿¡æ¯
            self.model_info.update({
                'type': 'MonAI_Bundle_Model',
                'network_class': network_config.__class__.__name__,
                'config_parser_used': True,
                'config_file': config_file.name,
                'bundle_path': str(self.bundle_path)
            })

            return True

        except Exception as e:
            print(f"   ConfigParseråŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def _load_config_manually(self, config_file):
        """æ‰‹åŠ¨åŠ è½½é…ç½®æ–‡ä»¶"""
        print("   æ‰‹åŠ¨åŠ è½½é…ç½®æ–‡ä»¶...")

        try:
            if config_file.suffix.lower() == '.json':
                with open(config_file, 'r', encoding='utf-8') as f:
                    self.config = json.load(f)
            elif config_file.suffix.lower() in ['.yaml', '.yml']:
                with open(config_file, 'r', encoding='utf-8') as f:
                    self.config = yaml.safe_load(f)
            else:
                raise ValueError(f"ä¸æ”¯æŒçš„é…ç½®æ–‡ä»¶æ ¼å¼: {config_file.suffix}")

            print(f"   æ‰‹åŠ¨é…ç½®åŠ è½½æˆåŠŸï¼ŒåŒ…å« {len(self.config)} ä¸ªé¡¶çº§é”®")

        except Exception as e:
            print(f"   æ‰‹åŠ¨é…ç½®åŠ è½½å¤±è´¥: {e}")
            self.config = {}

    def _create_fallback_model(self):
        """åˆ›å»ºå¤‡ç”¨æ¨¡å‹ï¼ˆåŸºäºLUNA16æ ‡å‡†ï¼‰"""
        print("   åˆ›å»ºLUNA16å…¼å®¹çš„å¤‡ç”¨æ¨¡å‹...")

        try:
            # æ ¹æ®LUNA16 READMEï¼Œä½¿ç”¨RetinaNetè¿›è¡Œæ£€æµ‹
            # å¦‚æœRetinaNetä¸å¯ç”¨ï¼Œä½¿ç”¨3D UNetä½œä¸ºå¤‡ç”¨

            # é¦–å…ˆå°è¯•RetinaNet
            try:
                from monai.apps.detection.networks.retinanet_network import RetinaNet

                model = RetinaNet(
                    spatial_dims=3,
                    n_input_channels=1,
                    num_classes=1,  # è‚ºç»“èŠ‚æ£€æµ‹
                    conv1_t_size=[7, 7, 7],
                    conv1_t_stride=[2, 2, 2],
                    returned_layers=[2, 3, 4],
                    num_anchors=3
                )

                print("   åˆ›å»ºRetinaNetæ¨¡å‹æˆåŠŸ")
                self.model_info.update({
                    'type': 'RetinaNet_3D_Fallback',
                    'network_class': 'RetinaNet',
                    'spatial_dims': 3,
                    'num_classes': 1
                })

                return model

            except ImportError:
                print("   RetinaNetä¸å¯ç”¨ï¼Œä½¿ç”¨3D UNet...")

                # å¤‡ç”¨ï¼š3D UNet
                model = BasicUNet(
                    spatial_dims=3,
                    in_channels=1,
                    out_channels=2,  # èƒŒæ™¯ + ç»“èŠ‚
                    features=(32, 64, 128, 256, 512, 32),
                    act=("LeakyReLU", {"inplace": True}),
                    norm=("instance", {"affine": True}),
                    dropout=0.1
                )

                print("   åˆ›å»º3D UNetæ¨¡å‹æˆåŠŸ")
                self.model_info.update({
                    'type': '3D_UNet_Fallback',
                    'network_class': 'BasicUNet',
                    'spatial_dims': 3,
                    'in_channels': 1,
                    'out_channels': 2
                })

                return model

        except Exception as e:
            print(f"   å¤‡ç”¨æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            raise

    def _load_weights_manually(self):
        """æ‰‹åŠ¨åŠ è½½æƒé‡ - ä¿®æ­£æˆåŠŸç‡è®¡ç®—"""
        print("   æ‰‹åŠ¨æŸ¥æ‰¾å’ŒåŠ è½½æƒé‡...")

        try:
            # æŸ¥æ‰¾æƒé‡æ–‡ä»¶
            weight_patterns = [
                "models/model.pt",
                "models/model.pth",
                "model.pt",
                "model.pth",
                "**/model*.pt",
                "**/model*.pth"
            ]

            weight_file = None
            for pattern in weight_patterns:
                weight_files = list(self.bundle_dir.glob(pattern))
                if weight_files:
                    weight_file = weight_files[0]
                    print(f"   æ‰¾åˆ°æƒé‡æ–‡ä»¶: {pattern} -> {weight_file.name}")
                    break

            if not weight_file:
                print("   âš ï¸ æœªæ‰¾åˆ°æƒé‡æ–‡ä»¶")
                self.model_info['weights_loaded'] = False
                self.model_info['load_ratio'] = 0.0
                return False

            # åŠ è½½æƒé‡
            print(f"   åŠ è½½æƒé‡æ–‡ä»¶: {weight_file}")
            checkpoint = torch.load(weight_file, map_location=self.device)

            # æå–state_dict
            state_dict = self._extract_state_dict(checkpoint)

            # æ¸…ç†é”®å
            cleaned_state_dict = self._clean_state_dict_keys(state_dict)

            # ğŸ”¥ ä¿®æ­£ï¼šåŠ è½½åˆ°æ¨¡å‹å‰å…ˆç¡®ä¿æ¨¡å‹å­˜åœ¨
            if self.model is not None:
                try:
                    # è·å–æ¨¡å‹çš„æœŸæœ›å‚æ•°
                    model_state_dict = self.model.state_dict()
                    total_model_keys = len(model_state_dict)

                    print(f"   æ¨¡å‹æœŸæœ›å‚æ•°æ•°é‡: {total_model_keys}")
                    print(f"   æƒé‡æ–‡ä»¶å‚æ•°æ•°é‡: {len(cleaned_state_dict)}")

                    # ğŸ”¥ ä¿®æ­£ï¼šæ›´æ™ºèƒ½çš„æƒé‡åŒ¹é…
                    matched_weights = {}
                    successful_matches = 0

                    for model_key in model_state_dict.keys():
                        # å°è¯•ç›´æ¥åŒ¹é…
                        if model_key in cleaned_state_dict:
                            matched_weights[model_key] = cleaned_state_dict[model_key]
                            successful_matches += 1
                        else:
                            # å°è¯•éƒ¨åˆ†åŒ¹é…
                            for weight_key in cleaned_state_dict.keys():
                                if model_key.endswith(weight_key) or weight_key.endswith(model_key):
                                    # æ£€æŸ¥å½¢çŠ¶æ˜¯å¦åŒ¹é…
                                    if model_state_dict[model_key].shape == cleaned_state_dict[weight_key].shape:
                                        matched_weights[model_key] = cleaned_state_dict[weight_key]
                                        successful_matches += 1
                                        print(f"   éƒ¨åˆ†åŒ¹é…: {model_key} <- {weight_key}")
                                        break

                    print(f"   æˆåŠŸåŒ¹é…å‚æ•°: {successful_matches}/{total_model_keys}")

                    # åŠ è½½åŒ¹é…çš„æƒé‡
                    missing_keys, unexpected_keys = self.model.load_state_dict(matched_weights, strict=False)

                    # ğŸ”¥ ä¿®æ­£ï¼šæ­£ç¡®è®¡ç®—åŠ è½½æˆåŠŸç‡
                    loaded_keys = total_model_keys - len(missing_keys)
                    load_ratio = loaded_keys / total_model_keys if total_model_keys > 0 else 0

                    print(f"   æƒé‡åŠ è½½å®Œæˆ:")
                    print(f"     æ¨¡å‹æ€»å‚æ•°: {total_model_keys}")
                    print(f"     æˆåŠŸåŠ è½½: {loaded_keys}")
                    print(f"     åŠ è½½ç‡: {load_ratio:.2%}")
                    print(f"     ç¼ºå¤±é”®: {len(missing_keys)}")
                    print(f"     æ„å¤–é”®: {len(unexpected_keys)}")

                    # å¦‚æœåŠ è½½ç‡ä»ç„¶ä¸º0ï¼Œå°è¯•å…¶ä»–ç­–ç•¥
                    if load_ratio == 0:
                        print("   âš ï¸ æ ‡å‡†åŠ è½½å¤±è´¥ï¼Œå°è¯•å¼ºåˆ¶åŒ¹é…...")
                        load_ratio = self._force_weight_loading(cleaned_state_dict)

                    self.model_info.update({
                        'weights_loaded': load_ratio > 0.1,  # é™ä½é˜ˆå€¼
                        'load_ratio': load_ratio,
                        'missing_keys': len(missing_keys),
                        'unexpected_keys': len(unexpected_keys),
                        'weight_file': weight_file.name,
                        'successful_matches': successful_matches,
                        'total_model_params': total_model_keys
                    })

                    return load_ratio > 0.1

                except Exception as e:
                    print(f"   æƒé‡åŠ è½½è¿‡ç¨‹å¤±è´¥: {e}")
                    self.model_info['weights_loaded'] = False
                    self.model_info['load_ratio'] = 0.0
                    return False

            return False

        except Exception as e:
            print(f"   æƒé‡åŠ è½½å¤±è´¥: {e}")
            self.model_info['weights_loaded'] = False
            self.model_info['load_ratio'] = 0.0
            return False

    def _force_weight_loading(self, cleaned_state_dict):
        """å¼ºåˆ¶æƒé‡åŠ è½½ç­–ç•¥"""
        try:
            print("   æ‰§è¡Œå¼ºåˆ¶æƒé‡åŒ¹é…...")

            model_state_dict = self.model.state_dict()
            total_params = len(model_state_dict)
            loaded_params = 0

            # ç­–ç•¥1: å°è¯•å½¢çŠ¶åŒ¹é…
            for model_key, model_param in model_state_dict.items():
                for weight_key, weight_param in cleaned_state_dict.items():
                    if model_param.shape == weight_param.shape:
                        try:
                            model_param.data.copy_(weight_param.data)
                            loaded_params += 1
                            print(f"   å¼ºåˆ¶åŒ¹é…: {model_key} <- {weight_key}")
                            break
                        except:
                            continue

            # ç­–ç•¥2: å¦‚æœä»ç„¶æ²¡æœ‰åŠ è½½ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…
            if loaded_params == 0:
                print("   å°è¯•éƒ¨åˆ†å‚æ•°åŒ¹é…...")
                # è¿™é‡Œå¯ä»¥æ·»åŠ æ›´å¤æ‚çš„åŒ¹é…é€»è¾‘

            force_ratio = loaded_params / total_params if total_params > 0 else 0
            print(f"   å¼ºåˆ¶åŒ¹é…ç»“æœ: {loaded_params}/{total_params} ({force_ratio:.2%})")

            return force_ratio

        except Exception as e:
            print(f"   å¼ºåˆ¶åŠ è½½å¤±è´¥: {e}")
            return 0.0

    def _extract_state_dict(self, checkpoint):
        """ä»checkpointæå–state_dict"""
        if isinstance(checkpoint, dict):
            # å°è¯•ä¸åŒçš„é”®å
            possible_keys = ['model', 'state_dict', 'model_state_dict', 'network', 'detector']

            for key in possible_keys:
                if key in checkpoint:
                    print(f"   ä½¿ç”¨checkpointé”®: {key}")
                    return checkpoint[key]

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†é”®åï¼Œä½¿ç”¨æ•´ä¸ªcheckpoint
            print("   ä½¿ç”¨æ•´ä¸ªcheckpointä½œä¸ºstate_dict")
            return checkpoint
        else:
            # ç›´æ¥æ˜¯state_dict
            return checkpoint

    def _clean_state_dict_keys(self, state_dict):
        """æ¸…ç†state_dictçš„é”®å"""
        cleaned_dict = {}

        for key, value in state_dict.items():
            # ç§»é™¤å¸¸è§çš„å‰ç¼€
            clean_key = key
            prefixes_to_remove = ['module.', 'model.', 'network.', 'detector.', '_orig_mod.']

            for prefix in prefixes_to_remove:
                if clean_key.startswith(prefix):
                    clean_key = clean_key[len(prefix):]
                    break

            cleaned_dict[clean_key] = value

        print(f"   é”®åæ¸…ç†å®Œæˆ: {len(state_dict)} -> {len(cleaned_dict)}")
        return cleaned_dict

    def _validate_model(self):
        """éªŒè¯æ¨¡å‹"""
        print("   éªŒè¯æ¨¡å‹...")

        try:
            if self.model is None:
                raise ValueError("æ¨¡å‹ä¸ºç©º")

            # ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            self.model = self.model.to(self.device)
            self.model.eval()

            # æµ‹è¯•æ¨ç†ï¼ˆä½¿ç”¨LUNA16æ ‡å‡†è¾“å…¥å°ºå¯¸ï¼‰
            test_input = torch.randn(1, 1, 80, 192, 192, device=self.device)  # LUNA16æ ‡å‡†å°ºå¯¸

            with torch.no_grad():
                try:
                    output = self.model(test_input)
                    print(f"   æ¨¡å‹éªŒè¯æˆåŠŸï¼Œè¾“å‡ºç±»å‹: {type(output)}")

                    if isinstance(output, dict):
                        print(f"   è¾“å‡ºé”®: {list(output.keys())}")
                    elif isinstance(output, (list, tuple)):
                        print(f"   è¾“å‡ºåˆ—è¡¨é•¿åº¦: {len(output)}")
                    elif isinstance(output, torch.Tensor):
                        print(f"   è¾“å‡ºå½¢çŠ¶: {output.shape}")

                    self.model_info['validation_passed'] = True
                    return True

                except Exception as e:
                    print(f"   æ¨¡å‹å‰å‘ä¼ æ’­å¤±è´¥: {e}")
                    self.model_info['validation_passed'] = False
                    return False

        except Exception as e:
            print(f"   æ¨¡å‹éªŒè¯å¤±è´¥: {e}")
            self.model_info['validation_passed'] = False
            return False

    def _print_model_info(self):
        """æ‰“å°æ¨¡å‹ä¿¡æ¯"""
        print("\nğŸ“Š æ¨¡å‹ä¿¡æ¯æ€»ç»“:")
        print("=" * 50)

        for key, value in self.model_info.items():
            print(f"   {key}: {value}")

        if self.model is not None:
            total_params = sum(p.numel() for p in self.model.parameters())
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)

            print(f"   total_parameters: {total_params:,}")
            print(f"   trainable_parameters: {trainable_params:,}")
            print(f"   model_size_mb: {total_params * 4 / 1024 / 1024:.2f}")

        print("=" * 50)

    def get_model(self):
        """è·å–åŠ è½½çš„æ¨¡å‹"""
        if self.model is not None:
            self.model = self.model.to(self.device)
            self.model.eval()
        return self.model

    def get_model_info(self):
        """è·å–æ¨¡å‹ä¿¡æ¯"""
        return self.model_info.copy()

    def get_config(self):
        """è·å–é…ç½®"""
        if hasattr(self, 'parser'):
            return self.parser.config
        else:
            return self.config

    def cleanup(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            if self.bundle_dir and self.bundle_dir != self.bundle_path:
                # åªæ¸…ç†ä¸´æ—¶è§£å‹çš„ç›®å½•
                if 'tmp' in str(self.bundle_dir) or 'temp' in str(self.bundle_dir):
                    import shutil
                    shutil.rmtree(self.bundle_dir, ignore_errors=True)
                    print(f"   æ¸…ç†ä¸´æ—¶ç›®å½•: {self.bundle_dir}")
        except Exception as e:
            print(f"   æ¸…ç†å¤±è´¥: {e}")


def test_bundle_loader():
    """æµ‹è¯•BundleåŠ è½½å™¨"""
    print("ğŸ§ª æµ‹è¯•BundleåŠ è½½å™¨")
    print(f"   å½“å‰ç”¨æˆ·: veryjoyran")
    print(f"   æ—¶é—´: 2025-06-24 15:25:42")

    # æµ‹è¯•è·¯å¾„
    bundle_path = "lung_nodule_ct_detection_v0.5.9.zip"

    if Path(bundle_path).exists():
        loader = MonAIBundleLoader(bundle_path, 'cpu')
        success = loader.load_bundle()

        if success:
            model = loader.get_model()
            info = loader.get_model_info()

            print(f"âœ… BundleåŠ è½½æµ‹è¯•æˆåŠŸ")
            print(f"   æ¨¡å‹ç±»å‹: {info.get('network_class', 'æœªçŸ¥')}")
            print(f"   æƒé‡åŠ è½½: {info.get('weights_loaded', False)}")
        else:
            print("âš ï¸ BundleåŠ è½½æµ‹è¯•éƒ¨åˆ†æˆåŠŸï¼ˆä½¿ç”¨å¤‡ç”¨æ¨¡å‹ï¼‰")

        loader.cleanup()
    else:
        print(f"âŒ æµ‹è¯•æ–‡ä»¶ä¸å­˜åœ¨: {bundle_path}")


if __name__ == "__main__":
    test_bundle_loader()