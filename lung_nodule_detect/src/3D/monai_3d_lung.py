import os
import torch
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import SimpleITK as sitk
import tempfile
import json
from datetime import datetime

import monai
from monai.apps import download_and_extract
from monai.bundle import ConfigParser, download, load
from monai.data import CacheDataset, DataLoader, decollate_batch
from monai.inferers import sliding_window_inference
from monai.metrics import DiceMetric
from monai.networks.nets import BasicUNet, UNETR, SwinUNETR
from monai.transforms import (
    Activations, AsDiscrete, Compose, LoadImaged,
    EnsureChannelFirstd,  # æ­£ç¡®çš„ç”¨æ³•
    Spacingd, Orientationd, ScaleIntensityRanged, CropForegroundd,
    RandCropByPosNegLabeld, ToTensord, EnsureTyped
)
from monai.utils import first, set_determinism

print(f"ğŸ”§ MonAIç‰ˆæœ¬: {monai.__version__}")
print(f"ğŸ”§ PyTorchç‰ˆæœ¬: {torch.__version__}")
print(f"ğŸ”§ è®¾å¤‡: {'CUDA' if torch.cuda.is_available() else 'CPU'}")


class MonAI3DLungDetector:
    """åŸºäºMonAIçš„3Dè‚ºç»“èŠ‚æ£€æµ‹å™¨ """

    def __init__(self, device=None):
        self.device = device or ('cuda' if torch.cuda.is_available() else 'cpu')
        self.model = None
        self.transforms = None
        self.model_info = {}

        # è®¾ç½®ç¡®å®šæ€§è®­ç»ƒ
        set_determinism(seed=12345)

        print(f"ğŸš€ åˆå§‹åŒ–MonAI 3Dæ£€æµ‹å™¨ (è®¾å¤‡: {self.device})")

    def setup_transforms(self):
        """è®¾ç½®æ•°æ®é¢„å¤„ç†å˜æ¢ - ä¿®æ­£ç‰ˆæœ¬"""
        print("ğŸ”§ è®¾ç½®æ•°æ®é¢„å¤„ç†æµæ°´çº¿...")

        # è®­ç»ƒå˜æ¢ - ä½¿ç”¨æ­£ç¡®çš„transforms
        self.train_transforms = Compose([
            LoadImaged(keys=["image", "label"]),
            EnsureChannelFirstd(keys=["image", "label"]),  # æ­£ç¡®çš„ç”¨æ³•
            Spacingd(
                keys=["image", "label"],
                pixdim=(1.0, 1.0, 1.0),
                mode=("bilinear", "nearest"),
            ),
            Orientationd(keys=["image", "label"], axcodes="RAS"),
            ScaleIntensityRanged(
                keys=["image"],
                a_min=-1000,
                a_max=400,
                b_min=0.0,
                b_max=1.0,
                clip=True,
            ),
            CropForegroundd(keys=["image", "label"], source_key="image"),
            RandCropByPosNegLabeld(
                keys=["image", "label"],
                label_key="label",
                spatial_size=(96, 96, 96),
                pos=1,
                neg=1,
                num_samples=2,
                image_key="image",
                image_threshold=0,
            ),
            ToTensord(keys=["image", "label"]),
        ])

        # éªŒè¯/æ¨ç†å˜æ¢ - ç®€åŒ–ç‰ˆæœ¬ï¼Œé¿å…å¯èƒ½çš„é—®é¢˜
        self.val_transforms = Compose([
            LoadImaged(keys=["image"]),
            EnsureChannelFirstd(keys=["image"]),  # ç¡®ä¿é€šé“åœ¨ç¬¬ä¸€ç»´
            Spacingd(keys=["image"], pixdim=(1.0, 1.0, 1.0), mode="bilinear"),
            Orientationd(keys=["image"], axcodes="RAS"),
            ScaleIntensityRanged(
                keys=["image"],
                a_min=-1000,
                a_max=400,
                b_min=0.0,
                b_max=1.0,
                clip=True,
            ),
            CropForegroundd(keys=["image"], source_key="image"),
            ToTensord(keys=["image"]),
        ])

        print("âœ… æ•°æ®é¢„å¤„ç†æµæ°´çº¿è®¾ç½®å®Œæˆ")

    def download_pretrained_models(self):
        """ä¸‹è½½MonAIé¢„è®­ç»ƒæ¨¡å‹ - ä¿®æ­£ç‰ˆæœ¬"""
        print("ğŸ“¥ ä¸‹è½½MonAIé¢„è®­ç»ƒæ¨¡å‹...")

        # åˆ›å»ºæ¨¡å‹å­˜å‚¨ç›®å½•
        self.model_dir = Path("./monai_models")
        self.model_dir.mkdir(exist_ok=True)

        # å°è¯•ä¸‹è½½å¯ç”¨çš„é¢„è®­ç»ƒæ¨¡å‹
        downloaded_models = {}

        # æ–¹æ³•1: å°è¯•ä¸‹è½½ä¸“ç”¨è‚ºç»“èŠ‚æ¨¡å‹
        try:
            print("ğŸ”„ å°è¯•ä¸‹è½½è‚ºç»“èŠ‚ä¸“ç”¨æ¨¡å‹...")

            # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªæ›´é€šç”¨çš„æ–¹æ³•
            # é¦–å…ˆå°è¯•ä»MonAI hubè·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
            from monai.bundle import get_bundle_versions

            try:
                # å°è¯•è·å–å¯ç”¨çš„bundle
                available_bundles = ["spleen_ct_segmentation", "lung_nodule_ct_detection"]

                for bundle_name in available_bundles:
                    try:
                        print(f"   å°è¯•ä¸‹è½½: {bundle_name}")
                        bundle_path = download(
                            name=bundle_name,
                            source="monaihosting",
                            progress=True,
                            cache_dir=str(self.model_dir)
                        )

                        downloaded_models[bundle_name] = {
                            "path": bundle_path,
                            "description": f"MonAI {bundle_name} model"
                        }

                        print(f"âœ… {bundle_name} ä¸‹è½½å®Œæˆ")
                        break  # æˆåŠŸä¸‹è½½ä¸€ä¸ªå°±é€€å‡º

                    except Exception as e:
                        print(f"   {bundle_name} ä¸‹è½½å¤±è´¥: {e}")
                        continue

            except Exception as e:
                print(f"   Bundleä¸‹è½½å¤±è´¥: {e}")

        except Exception as e:
            print(f"âš ï¸ ä¸“ç”¨æ¨¡å‹ä¸‹è½½å¤±è´¥: {e}")

        # æ–¹æ³•2: å¦‚æœæ²¡æœ‰ä¸‹è½½æˆåŠŸï¼Œä½¿ç”¨é¢„æ„å»ºçš„æ¨¡å‹
        if not downloaded_models:
            print("âš ï¸ æœªèƒ½ä¸‹è½½ä¸“ç”¨æ¨¡å‹ï¼Œå°†åˆ›å»ºé€šç”¨é¢„è®­ç»ƒæ¨¡å‹")
            self._setup_generic_pretrained()
        else:
            self.downloaded_models = downloaded_models

        return downloaded_models

    def _setup_generic_pretrained(self):
        """è®¾ç½®é€šç”¨é¢„è®­ç»ƒæ¨¡å‹ - æ”¹è¿›ç‰ˆæœ¬"""
        print("ğŸ”§ è®¾ç½®é€šç”¨é¢„è®­ç»ƒæ¨¡å‹...")

        try:
            # å°è¯•åˆ›å»ºUNETRæ¨¡å‹ï¼ˆæ›´å…ˆè¿›ï¼‰
            self.model = UNETR(
                in_channels=1,
                out_channels=2,  # èƒŒæ™¯ + ç»“èŠ‚
                img_size=(96, 96, 96),
                feature_size=16,
                hidden_size=768,
                mlp_dim=3072,
                num_heads=12,
                pos_embed="perceptron",
                norm_name="instance",
                res_block=True,
                dropout_rate=0.0,
            ).to(self.device)

            print("âœ… UNETRæ¨¡å‹åˆ›å»ºå®Œæˆ")

            # è®¾ç½®æ¨¡å‹ä¿¡æ¯
            self.model_info = {
                "type": "UNETR",
                "pretrained": False,
                "input_channels": 1,
                "output_channels": 2,
                "spatial_dims": 3,
                "img_size": (96, 96, 96)
            }

        except Exception as e:
            print(f"âš ï¸ UNETRåˆ›å»ºå¤±è´¥: {e}ï¼Œä½¿ç”¨BasicUNet")

            # å¤‡ç”¨æ–¹æ¡ˆï¼šBasicUNet
            self.model = BasicUNet(
                spatial_dims=3,
                in_channels=1,
                out_channels=2,  # èƒŒæ™¯ + ç»“èŠ‚
                features=(32, 32, 64, 128, 256, 32),
                dropout=0.1
            ).to(self.device)

            print("âœ… BasicUNetæ¨¡å‹åˆ›å»ºå®Œæˆ")

            # è®¾ç½®æ¨¡å‹ä¿¡æ¯
            self.model_info = {
                "type": "BasicUNet",
                "pretrained": False,
                "input_channels": 1,
                "output_channels": 2,
                "spatial_dims": 3
            }

    def load_bundle_model(self, bundle_name="spleen_ct_segmentation"):
        """åŠ è½½Bundleæ¨¡å‹ - æ”¹è¿›ç‰ˆæœ¬"""
        try:
            if hasattr(self, 'downloaded_models') and bundle_name in self.downloaded_models:
                bundle_path = self.downloaded_models[bundle_name]["path"]

                print(f"ğŸ”„ åŠ è½½Bundleæ¨¡å‹: {bundle_name}")
                print(f"   è·¯å¾„: {bundle_path}")

                # æ£€æŸ¥bundleç»“æ„
                bundle_dir = Path(bundle_path)
                config_files = list(bundle_dir.rglob("*.json"))
                model_files = list(bundle_dir.rglob("*.pt")) + list(bundle_dir.rglob("*.pth"))

                print(f"   æ‰¾åˆ°é…ç½®æ–‡ä»¶: {len(config_files)}")
                print(f"   æ‰¾åˆ°æ¨¡å‹æ–‡ä»¶: {len(model_files)}")

                if config_files and model_files:
                    try:
                        # ä½¿ç”¨MonAIçš„BundleåŠ è½½å™¨
                        parser = ConfigParser()
                        parser.read_config(str(config_files[0]))

                        # å°è¯•è·å–ç½‘ç»œå®šä¹‰
                        if "network_def" in parser.config:
                            self.model = parser.get_parsed_content("network_def")
                            self.model = self.model.to(self.device)

                            # åŠ è½½æƒé‡
                            checkpoint = torch.load(model_files[0], map_location=self.device)

                            # å¤„ç†ä¸åŒçš„æƒé‡æ ¼å¼
                            if isinstance(checkpoint, dict):
                                if "model" in checkpoint:
                                    state_dict = checkpoint["model"]
                                elif "state_dict" in checkpoint:
                                    state_dict = checkpoint["state_dict"]
                                elif "model_state_dict" in checkpoint:
                                    state_dict = checkpoint["model_state_dict"]
                                else:
                                    state_dict = checkpoint
                            else:
                                state_dict = checkpoint

                            # å°è¯•åŠ è½½æƒé‡
                            try:
                                self.model.load_state_dict(state_dict, strict=False)
                                print(f"âœ… Bundleæ¨¡å‹åŠ è½½å®Œæˆ: {bundle_name}")

                                self.model_info = {
                                    "type": "Bundle",
                                    "name": bundle_name,
                                    "pretrained": True,
                                    "path": str(bundle_path)
                                }

                                return True

                            except Exception as e:
                                print(f"âš ï¸ æƒé‡åŠ è½½å¤±è´¥: {e}")

                    except Exception as e:
                        print(f"âš ï¸ Bundleè§£æå¤±è´¥: {e}")

                print(f"âš ï¸ Bundleæ–‡ä»¶ç»“æ„ä¸å®Œæ•´")

            # å¦‚æœBundleåŠ è½½å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ
            print("ğŸ”„ BundleåŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é€šç”¨æ¨¡å‹")
            self._setup_generic_pretrained()
            return False

        except Exception as e:
            print(f"âŒ Bundleæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self._setup_generic_pretrained()
            return False

    def convert_dicom_to_nifti(self, dicom_path):
        """å°†DICOMè½¬æ¢ä¸ºNIfTIæ ¼å¼ - æ”¹è¿›ç‰ˆæœ¬"""
        print(f"ğŸ”„ è½¬æ¢DICOM: {dicom_path}")

        try:
            if Path(dicom_path).is_dir():
                # DICOMåºåˆ—ç›®å½•
                reader = sitk.ImageSeriesReader()
                dicom_names = reader.GetGDCMSeriesFileNames(str(dicom_path))

                if not dicom_names:
                    raise ValueError("ç›®å½•ä¸­æœªæ‰¾åˆ°DICOMæ–‡ä»¶")

                reader.SetFileNames(dicom_names)
                image = reader.Execute()

                print(f"   è¯»å–DICOMåºåˆ—: {len(dicom_names)} ä¸ªæ–‡ä»¶")

            else:
                # å•ä¸ªDICOMæ–‡ä»¶
                image = sitk.ReadImage(str(dicom_path))
                print(f"   è¯»å–å•ä¸ªDICOMæ–‡ä»¶")

            # è·å–åŸºæœ¬ä¿¡æ¯
            print(f"   åŸå§‹å°ºå¯¸: {image.GetSize()}")
            print(f"   ä½“ç´ é—´è·: {image.GetSpacing()}")
            print(f"   æ–¹å‘: {image.GetDirection()}")

            # æ ‡å‡†åŒ–æ–¹å‘
            image = sitk.DICOMOrient(image, 'LPS')

            # è½¬æ¢ä¸ºHUå€¼
            array = sitk.GetArrayFromImage(image)
            print(f"   HUå€¼èŒƒå›´: [{array.min():.1f}, {array.max():.1f}]")

            # ä¿å­˜ä¸ºä¸´æ—¶NIfTIæ–‡ä»¶
            temp_file = tempfile.mktemp(suffix='.nii.gz')
            sitk.WriteImage(image, temp_file)

            print(f"âœ… è½¬æ¢å®Œæˆ: {temp_file}")

            return temp_file, image

        except Exception as e:
            print(f"âŒ DICOMè½¬æ¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None, None

    def inference_on_volume(self, nifti_path, roi_size=(96, 96, 96), sw_batch_size=4):
        """å¯¹3Dä½“ç§¯è¿›è¡Œæ¨ç† - æ”¹è¿›ç‰ˆæœ¬"""
        if self.model is None:
            print("âŒ æ¨¡å‹æœªåŠ è½½")
            return None

        print(f"ğŸ” å¼€å§‹3Dæ¨ç†: {nifti_path}")
        print(f"   ROIå°ºå¯¸: {roi_size}")
        print(f"   æ‰¹å¤„ç†å¤§å°: {sw_batch_size}")

        try:
            # å‡†å¤‡æ•°æ®
            data_dict = {"image": nifti_path}

            # åº”ç”¨é¢„å¤„ç†
            if self.val_transforms is None:
                self.setup_transforms()

            data_dict = self.val_transforms(data_dict)

            # æ£€æŸ¥æ•°æ®å½¢çŠ¶
            input_tensor = data_dict["image"]
            print(f"   é¢„å¤„ç†åå½¢çŠ¶: {input_tensor.shape}")

            # ç¡®ä¿æœ‰æ‰¹æ¬¡ç»´åº¦
            if input_tensor.dim() == 4:  # (C, D, H, W)
                input_tensor = input_tensor.unsqueeze(0)  # (1, C, D, H, W)

            input_tensor = input_tensor.to(self.device)
            print(f"   è¾“å…¥å¼ é‡å½¢çŠ¶: {input_tensor.shape}")

            # æ£€æŸ¥è¾“å…¥å°ºå¯¸æ˜¯å¦åˆé€‚
            _, _, d, h, w = input_tensor.shape
            if d < roi_size[0] or h < roi_size[1] or w < roi_size[2]:
                print(f"âš ï¸ è¾“å…¥ä½“ç§¯å¤ªå° ({d}, {h}, {w})ï¼Œè°ƒæ•´ROIå°ºå¯¸")
                roi_size = (min(d, roi_size[0]), min(h, roi_size[1]), min(w, roi_size[2]))
                print(f"   è°ƒæ•´åROIå°ºå¯¸: {roi_size}")

            # æ¨ç†
            self.model.eval()
            with torch.no_grad():
                # ä½¿ç”¨æ»‘åŠ¨çª—å£æ¨ç†å¤„ç†å¤§ä½“ç§¯
                outputs = sliding_window_inference(
                    inputs=input_tensor,
                    roi_size=roi_size,
                    sw_batch_size=sw_batch_size,
                    predictor=self.model,
                    overlap=0.25,
                    mode="gaussian",
                    sigma_scale=0.125,
                    padding_mode="constant",
                    cval=0.0,
                )

                print(f"   æ¨ç†è¾“å‡ºå½¢çŠ¶: {outputs.shape}")

                # åå¤„ç†
                outputs = torch.softmax(outputs, dim=1)
                pred_mask = torch.argmax(outputs, dim=1).squeeze(0)
                prob_map = outputs[0, 1]  # ç»“èŠ‚æ¦‚ç‡å›¾

                # è½¬æ¢ä¸ºnumpy
                pred_np = pred_mask.cpu().numpy()
                prob_np = prob_map.cpu().numpy()

                print(f"âœ… æ¨ç†å®Œæˆ")
                print(f"   é¢„æµ‹å½¢çŠ¶: {pred_np.shape}")
                print(f"   é˜³æ€§ä½“ç´ : {np.sum(pred_np > 0)}")
                print(f"   æœ€å¤§æ¦‚ç‡: {prob_np.max():.3f}")

                return {
                    "prediction": pred_np,
                    "probability": prob_np,
                    "input_shape": input_tensor.shape,
                    "positive_voxels": int(np.sum(pred_np > 0)),
                    "max_probability": float(prob_np.max()),
                    "mean_probability": float(prob_np.mean())
                }

        except Exception as e:
            print(f"âŒ æ¨ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None

    def extract_nodule_candidates(self, prediction, probability, min_size=20, max_size=10000):
        """ä»é¢„æµ‹ç»“æœä¸­æå–ç»“èŠ‚å€™é€‰ - æ”¹è¿›ç‰ˆæœ¬"""
        print(f"ğŸ¯ æå–ç»“èŠ‚å€™é€‰ (æœ€å°å°ºå¯¸: {min_size}, æœ€å¤§å°ºå¯¸: {max_size})")

        try:
            from scipy import ndimage
            from skimage import measure

            # è¿é€šç»„ä»¶åˆ†æ
            labeled_array, num_features = ndimage.label(prediction > 0)

            print(f"   å‘ç°è¿é€šç»„ä»¶: {num_features} ä¸ª")

            candidates = []

            for i in range(1, num_features + 1):
                mask = (labeled_array == i)
                size = np.sum(mask)

                if min_size <= size <= max_size:
                    # è®¡ç®—è´¨å¿ƒ
                    center = ndimage.center_of_mass(mask)

                    # è®¡ç®—è¾¹ç•Œæ¡†
                    coords = np.where(mask)
                    bbox = [
                        int(coords[0].min()), int(coords[0].max()),
                        int(coords[1].min()), int(coords[1].max()),
                        int(coords[2].min()), int(coords[2].max())
                    ]

                    # è®¡ç®—æ¦‚ç‡ç»Ÿè®¡
                    region_probs = probability[mask]
                    avg_prob = float(region_probs.mean())
                    max_prob = float(region_probs.max())
                    std_prob = float(region_probs.std())

                    # è®¡ç®—å½¢çŠ¶ç‰¹å¾
                    try:
                        # ç®€å•çš„å½¢çŠ¶ç‰¹å¾
                        bbox_volume = (bbox[1] - bbox[0]) * (bbox[3] - bbox[2]) * (bbox[5] - bbox[4])
                        compactness = size / bbox_volume if bbox_volume > 0 else 0

                        # è®¡ç®—çƒå½¢åº¦ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
                        equivalent_diameter = (6 * size / np.pi) ** (1 / 3)
                        surface_area = np.sum(ndimage.binary_erosion(mask) != mask)  # è¿‘ä¼¼è¡¨é¢ç§¯
                        sphericity = (np.pi ** (1 / 3)) * (
                                    (6 * size) ** (2 / 3)) / surface_area if surface_area > 0 else 0

                    except:
                        compactness = 0.0
                        sphericity = 0.0

                    candidate = {
                        "id": i,
                        "center": [float(c) for c in center],  # ç¡®ä¿å¯JSONåºåˆ—åŒ–
                        "bbox": bbox,
                        "size": int(size),
                        "avg_probability": avg_prob,
                        "max_probability": max_prob,
                        "std_probability": std_prob,
                        "compactness": compactness,
                        "sphericity": min(sphericity, 1.0),  # é™åˆ¶åœ¨0-1ä¹‹é—´
                        "mask": mask
                    }

                    candidates.append(candidate)

            # æŒ‰æœ€å¤§æ¦‚ç‡æ’åº
            candidates = sorted(candidates, key=lambda x: x["max_probability"], reverse=True)

            print(f"âœ… æ‰¾åˆ° {len(candidates)} ä¸ªå€™é€‰ç»“èŠ‚")

            # æ˜¾ç¤ºå‰å‡ ä¸ªå€™é€‰çš„ä¿¡æ¯
            for i, cand in enumerate(candidates[:5]):
                print(
                    f"   å€™é€‰ {i + 1}: å°ºå¯¸={cand['size']}, æœ€å¤§æ¦‚ç‡={cand['max_probability']:.3f}, ç´§å¯†åº¦={cand['compactness']:.3f}")

            return candidates

        except Exception as e:
            print(f"âŒ å€™é€‰æå–å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return []

    def save_results(self, candidates, output_dir="./results"):
        """ä¿å­˜ç»“æœ - æ”¹è¿›ç‰ˆæœ¬"""
        output_path = Path(output_dir)
        output_path.mkdir(exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜å€™é€‰ä¿¡æ¯ä¸ºJSON
        candidates_clean = []
        for cand in candidates:
            cand_clean = {k: v for k, v in cand.items() if k != "mask"}  # å»é™¤maskï¼ˆæ— æ³•JSONåºåˆ—åŒ–ï¼‰
            candidates_clean.append(cand_clean)

        results_data = {
            "timestamp": timestamp,
            "user": "veryjoyran",
            "version": "v1.0.0_fixed",
            "model_info": self.model_info,
            "total_candidates": len(candidates_clean),
            "candidates": candidates_clean
        }

        json_path = output_path / f"monai_results_{timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(results_data, f, indent=2, ensure_ascii=False)

        print(f"ğŸ’¾ ç»“æœä¿å­˜è‡³: {json_path}")
        return json_path


# å¿«é€Ÿæµ‹è¯•å‡½æ•°
def quick_test_fixed_monai():
    """å¿«é€Ÿæµ‹è¯•ä¿®æ­£ç‰ˆMonAIæ£€æµ‹å™¨"""
    print("ğŸš€ å¼€å§‹æµ‹è¯•ä¿®æ­£ç‰ˆMonAI 3Dè‚ºç»“èŠ‚æ£€æµ‹å™¨")
    print(f"ğŸ‘¤ ç”¨æˆ·: veryjoyran")
    print(f"ğŸ“… æ—¶é—´: 2025-06-23 02:40:44")
    print("=" * 60)

    # 1. åˆå§‹åŒ–æ£€æµ‹å™¨
    detector = MonAI3DLungDetector()

    # 2. ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹
    print("\nğŸ“¥ ç¬¬1æ­¥: ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹...")
    downloaded_models = detector.download_pretrained_models()

    # 3. è®¾ç½®æ•°æ®å˜æ¢
    print("\nğŸ”§ ç¬¬2æ­¥: è®¾ç½®æ•°æ®å˜æ¢...")
    detector.setup_transforms()

    # 4. åŠ è½½æ¨¡å‹
    print("\nğŸ¤– ç¬¬3æ­¥: åŠ è½½æ¨¡å‹...")
    if downloaded_models:
        success = detector.load_bundle_model()
        if not success:
            print("   ä½¿ç”¨é€šç”¨æ¨¡å‹ä½œä¸ºå¤‡ç”¨")
    else:
        print("   ä½¿ç”¨é€šç”¨æ¨¡å‹")

    print(f"\nâœ… æ£€æµ‹å™¨åˆå§‹åŒ–å®Œæˆ!")
    print(f"   æ¨¡å‹ç±»å‹: {detector.model_info.get('type', 'Unknown')}")
    print(f"   é¢„è®­ç»ƒ: {detector.model_info.get('pretrained', False)}")
    print(f"   è®¾å¤‡: {detector.device}")

    # 5. æç¤ºç”¨æˆ·å¦‚ä½•ä½¿ç”¨
    print(f"\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    print(f"   1. å°†æ‚¨çš„DICOMæ•°æ®è·¯å¾„æ›¿æ¢åˆ°ä¸‹é¢çš„ä»£ç ä¸­")
    print(f"   2. è¿è¡Œæ¨ç†æµ‹è¯•")

    # ç¤ºä¾‹ä½¿ç”¨ä»£ç 
    example_code = '''
# ä½¿ç”¨ç¤ºä¾‹:
dicom_path = "path/to/your/dicom/series"  # æ›¿æ¢ä¸ºæ‚¨çš„è·¯å¾„

if Path(dicom_path).exists():
    # è½¬æ¢DICOM
    nifti_path, sitk_image = detector.convert_dicom_to_nifti(dicom_path)

    if nifti_path:
        # è¿›è¡Œæ¨ç†
        results = detector.inference_on_volume(nifti_path)

        if results:
            # æå–å€™é€‰
            candidates = detector.extract_nodule_candidates(
                results["prediction"], 
                results["probability"]
            )

            # ä¿å­˜ç»“æœ
            json_path = detector.save_results(candidates)

            print(f"æ£€æµ‹å®Œæˆï¼å‘ç° {len(candidates)} ä¸ªå€™é€‰ç»“èŠ‚")
'''

    print(example_code)

    return detector


if __name__ == "__main__":
    # æµ‹è¯•ä¿®æ­£ç‰ˆæ£€æµ‹å™¨
    detector = quick_test_fixed_monai()

    print("\nğŸ‰ MonAIæ£€æµ‹å™¨å‡†å¤‡å°±ç»ªï¼")
    print("   ç°åœ¨æ‚¨å¯ä»¥å¤„ç†å®é™…çš„DICOMæ•°æ®äº†")